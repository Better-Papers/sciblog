---
title: Representations
---

## How do we compare representations between ANNs and the brain?

Main idea: Simulating a primary visual cortex (V1) at the front of CNNs leads to small improvements in robustness to these image perturbations.
That is, representation performance should correlate with robustness.

### Method

- ANN Review [@yangArtificialNeural2020]
- Neural system identification [@klindtNeuralSystem2018]
- CKA [@kornblithSimilarityNeural2019]
- Critique of CKA, CCA [@dingGroundingRepresentation2021]
- How do transformers learn? [@bonhemeHowVariational2022]
- Gaussian process factor [@keeleyIdentifyingSignal2020]
- Normalizing flow [@bashiriFlowbasedLatent2021]

#### ANNs-ANNs

- Speech analysis [@pasadLayerwiseAnalysis2021]

#### How do different ANN architectures compare?

- CNN vs Transformer [[@raghuVisionTransformers2021]]

#### ANNs-Brain

Check out the [brain score](http://www.brain-score.org) competition.

- Primate data source [[@rajalinghamLargeScaleHighResolution2018]]
- Best performing model: [[@riedelBagTricks2022]]
- GRCNN [[@azeglioImprovingNeural2022]]

The human people have behavioral correlates, another training objective.

- State-of-the-art error consistency [[@geirhosPartialSuccess2021]]
- Shallow recurrent ANN, best ImageNet-1 and brainscore [@kubiliusBrainLikeObject2019]
- Combine different V1 models [@baidyaCombiningDifferent2021]
- Joint transformer model [@berriosJointRotational2022], compare with [[@bakhtiariFunctionalSpecialization2021]]
- Object representations in humans [@graumannSpatiotemporalNeural2022]

- Shallow unsupervised [@nayebiShallowUnsupervised2021]
- Mice, primate differences [@luongoMicePrimates2021]
- Digital twin Tolias [@ustyuzhaninovDigitalTwin2022]
- Transformer and MTL [@whittingtonRelatingTransformers2021]

#### Brain

- Task representations in neural networks trained to perform many cognitive tasks [@yangTaskRepresentations2019]
- Recurrence required [@kietzmannRecurrenceRequired2019]
- Robust vision through multi-task learning [@safaraniRobustVision2021]
