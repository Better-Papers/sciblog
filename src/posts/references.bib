
@article{abbottHowWorld2021,
  title = {How the World's Biggest Brain Maps Could Transform Neuroscience},
  author = {Abbott, Alison},
  year = {2021},
  month = oct,
  journal = {Nature},
  volume = {598},
  number = {7879},
  pages = {22--25},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-021-02661-w},
  abstract = {Scientists around the world are working together to catalogue and map cells in the brain. What have these huge projects revealed about how it works?},
  copyright = {2021 Nature},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: News Feature Subject\_term: Brain, Neuroscience, Cell biology, Databases}
}

@article{adesnikProbingNeural2021,
  title = {Probing Neural Codes with Two-Photon Holographic Optogenetics},
  author = {Adesnik, Hillel and Abdeladim, Lamiae},
  year = {2021},
  month = aug,
  journal = {Nat Neurosci},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00902-9},
  abstract = {Optogenetics ushered in a revolution in how neuroscientists interrogate brain function. Because of technical limitations, the majority of optogenetic studies have used low spatial resolution activation schemes that limit the types of perturbations that can be made. However, neural activity manipulations at finer spatial scales are likely to be important to more fully understand neural computation. Spatially precise multiphoton holographic optogenetics promises to address this challenge and opens up many new classes of experiments that were not previously possible. More specifically, by offering the ability to recreate extremely specific neural activity patterns in both space and time in functionally defined ensembles of neurons, multiphoton holographic optogenetics could allow neuroscientists to reveal fundamental aspects of the neural codes for sensation, cognition and behavior that have been beyond reach. This Review summarizes recent advances in multiphoton holographic optogenetics that substantially expand its capabilities, highlights outstanding technical challenges and provides an overview of the classes of experiments it can execute to test and validate key theoretical models of brain function. Multiphoton holographic optogenetics could substantially accelerate the pace of neuroscience discovery by helping to close the loop between experimental and theoretical neuroscience, leading to fundamental new insights into nervous system function and disorder.},
  copyright = {2021 Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Multiphoton microscopy;Neural circuits;Optogenetics Subject\_term\_id: multiphoton-microscopy;neural-circuit;optogenetics}
}

@article{aimoneRoadmapReaching2021,
  title = {A {{Roadmap}} for {{Reaching}} the {{Potential}} of {{Brain-Derived Computing}}},
  author = {Aimone, James B.},
  year = {2021},
  journal = {Advanced Intelligent Systems},
  volume = {3},
  number = {1},
  pages = {2000191},
  issn = {2640-4567},
  doi = {10.1002/aisy.202000191},
  abstract = {Neuromorphic computing is a critical future technology for the computing industry, but it has yet to achieve its promise and has struggled to establish a cohesive research community. A large part of the challenge is that full realization of the potential of brain inspiration requires advances in both device hardware, computing architectures, and algorithms. This simultaneous development across technology scales is unprecedented in the computing field. This article presents a strategy, framed by market and policy pressures, for moving past these current technological and cultural hurdles to realize its full impact across technology. Achieving the full potential of brain-derived algorithms as well as post-complementary metal\textendash oxide-semiconductor (CMOS) scaling neuromorphic hardware requires appropriately balancing the near-term opportunities of deep learning applications with the long-term potential of less understood opportunities in neural computing.},
  langid = {english},
  keywords = {artificial intelligence,brain,neural algorithms,neuromorphic computing},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202000191}
}

@article{ashtianiOnchipPhotonic2022,
  title = {An On-Chip Photonic Deep Neural Network for Image Classification},
  author = {Ashtiani, Farshid and Geers, Alexander J. and Aflatouni, Firooz},
  year = {2022},
  month = jun,
  journal = {Nature},
  pages = {1--6},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-04714-0},
  abstract = {Using a three-layer opto-electronic neural network, direct, clock-less sub-nanosecond image classification on a silicon photonics chip is demonstrated, achieving a classification time~comparable with a single clock cycle of state-of-the-art digital implementations.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Electrical and electronic engineering,Optics and photonics,Silicon photonics}
}

@article{azeglioImprovingNeural2022,
  title = {Improving {{Neural Predictivity}} in the {{Visual Cortex}} with {{Gated Recurrent Connections}}},
  author = {Azeglio, Simone and Poetto, Simone and Aira, Luca Savant and Nurisso, Marco},
  year = {2022},
  month = mar,
  doi = {10.48550/arXiv.2203.11910},
  abstract = {Computational models of vision have traditionally been developed in a bottom-up fashion, by hierarchically composing a series of straightforward operations - i.e. convolution and pooling - with the aim of emulating simple and complex cells in the visual cortex, resulting in the introduction of deep convolutional neural networks (CNNs). Nevertheless, data obtained with recent neuronal recording techniques support that the nature of the computations carried out in the ventral visual stream is not completely captured by current deep CNN models. To fill the gap between the ventral visual stream and deep models, several benchmarks have been designed and organized into the Brain-Score platform, granting a way to perform multi-layer (V1, V2, V4, IT) and behavioral comparisons between the two counterparts. In our work, we aim to shift the focus on architectures that take into account lateral recurrent connections, a ubiquitous feature of the ventral visual stream, to devise adaptive receptive fields. Through recurrent connections, the input s long-range spatial dependencies can be captured in a local multi-step fashion and, as introduced with Gated Recurrent CNNs (GRCNN), the unbounded expansion of the neuron s receptive fields can be modulated through the use of gates. In order to increase the robustness of our approach and the biological fidelity of the activations, we employ specific data augmentation techniques in line with several of the scoring benchmarks. Enforcing some form of invariance, through heuristics, was found to be beneficial for better neural predictivity.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Azeglio et al_2022_Improving Neural Predictivity in the Visual Cortex with Gated Recurrent.pdf}
}

@misc{baidyaCombiningDifferent2021,
  title = {Combining {{Different V1 Brain Model Variants}} to {{Improve Robustness}} to {{Image Corruptions}} in {{CNNs}}},
  author = {Baidya, Avinash and Dapello, Joel and DiCarlo, James J. and Marques, Tiago},
  year = {2021},
  month = dec,
  number = {arXiv:2110.10645},
  eprint = {2110.10645},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, q-bio},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2110.10645},
  abstract = {While some convolutional neural networks (CNNs) have surpassed human visual abilities in object classification, they often struggle to recognize objects in images corrupted with different types of common noise patterns, highlighting a major limitation of this family of models. Recently, it has been shown that simulating a primary visual cortex (V1) at the front of CNNs leads to small improvements in robustness to these image perturbations. In this study, we start with the observation that different variants of the V1 model show gains for specific corruption types. We then build a new model using an ensembling technique, which combines multiple individual models with different V1 front-end variants. The model ensemble leverages the strengths of each individual model, leading to significant improvements in robustness across all corruption categories and outperforming the base model by 38\% on average. Finally, we show that using distillation, it is possible to partially compress the knowledge in the ensemble model into a single model with a V1 front-end. While the ensembling and distillation techniques used here are hardly biologically-plausible, the results presented here demonstrate that by combining the specific strengths of different neuronal circuits in V1 it is possible to improve the robustness of CNNs for a wide range of perturbations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Baidya et al_2021_Combining Different V1 Brain Model Variants to Improve Robustness to Image.pdf}
}

@inproceedings{bakhtiariFunctionalSpecialization2021,
  title = {The Functional Specialization of Visual Cortex Emerges from Training Parallel Pathways with Self-Supervised Predictive Learning},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bakhtiari, Shahab and Mineault, Patrick J. and Lillicrap, Tim and Pack, Christopher C. and Richards, Blake Aaron},
  year = {2021},
  month = may,
  abstract = {Self-supervised predictive learning applied to a neural network with parallel pathways can account for some of the functional specialization of the visual systems.},
  langid = {english}
}

@inproceedings{bashiriFlowbasedLatent2021,
  title = {A Flow-Based Latent State Generative Model of Neural Population Responses to Natural Images},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bashiri, Mohammad and Walker, Edgar and Lurz, Konstantin-Klemens and Jagadish, Akshay and Muhammad, Taliah and Ding, Zhiwei and Ding, Zhuokun and Tolias, Andreas and Sinz, Fabian},
  year = {2021},
  volume = {34},
  pages = {15801--15815},
  publisher = {{Curran Associates, Inc.}},
  abstract = {We present a joint deep neural system identification model for two major sources of neural variability: stimulus-driven and stimulus-conditioned fluctuations. To this end, we combine (1) state-of-the-art deep networks for stimulus-driven activity and (2) a flexible, normalizing flow-based generative model to capture the stimulus-conditioned variability including noise correlations. This allows us to train the model end-to-end without the need for sophisticated probabilistic approximations associated with many latent state models for stimulus-conditioned fluctuations. We train the model on the responses of thousands of neurons from multiple areas of the mouse visual cortex to natural images. We show that our model outperforms previous state-of-the-art models in predicting the distribution of neural population responses to novel stimuli, including shared stimulus-conditioned variability. Furthermore, it successfully learns known latent factors of the population responses that are related to behavioral variables such as pupil dilation, and other factors that vary systematically with brain area or retinotopic location. Overall, our model accurately accounts for two critical sources of neural variability while avoiding several complexities associated with many existing latent state models. It thus provides a useful tool for uncovering the interplay between different factors that contribute to variability in neural activity.},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Bashiri et al_2021_A flow-based latent state generative model of neural population responses to.pdf}
}

@misc{berriosJointRotational2022,
  title = {Joint Rotational Invariance and Adversarial Training of a Dual-Stream {{Transformer}} Yields State of the Art {{Brain-Score}} for {{Area V4}}},
  author = {Berrios, William and Deza, Arturo},
  year = {2022},
  month = may,
  number = {arXiv:2203.06649},
  eprint = {2203.06649},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2203.06649},
  abstract = {Modern high-scoring models of vision in the brain score competition do not stem from Vision Transformers. However, in this paper, we provide evidence against the unexpected trend of Vision Transformers (ViT) being not perceptually aligned with human visual representations by showing how a dual-stream Transformer, a CrossViT\$\textasciitilde\textbackslash textit\{a la\}\$ Chen et al. (2021), under a joint rotationally-invariant and adversarial optimization procedure yields 2nd place in the aggregate Brain-Score 2022 competition(Schrimpf et al., 2020b) averaged across all visual categories, and at the time of the competition held 1st place for the highest explainable variance of area V4. In addition, our current Transformer-based model also achieves greater explainable variance for areas V4, IT and Behaviour than a biologically-inspired CNN (ResNet50) that integrates a frontal V1-like computation module (Dapello et al.,2020). To assess the contribution of the optimization scheme with respect to the CrossViT architecture, we perform several additional experiments on differently optimized CrossViT's regarding adversarial robustness, common corruption benchmarks, mid-ventral stimuli interpretation and feature inversion. Against our initial expectations, our family of results provides tentative support for an \$\textbackslash textit\{"All roads lead to Rome"\}\$ argument enforced via a joint optimization rule even for non biologically-motivated models of vision such as Vision Transformers. Code is available at https://github.com/williamberrios/BrainScore-Transformers},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Berrios_Deza_2022_Joint rotational invariance and adversarial training of a dual-stream.pdf}
}

@article{billehSystematicIntegration2020,
  title = {Systematic {{Integration}} of {{Structural}} and {{Functional Data}} into {{Multi-scale Models}} of {{Mouse Primary Visual Cortex}}},
  author = {Billeh, Yazan N. and Cai, Binghuang and Gratiy, Sergey L. and Dai, Kael and Iyer, Ramakrishnan and Gouwens, Nathan W. and {Abbasi-Asl}, Reza and Jia, Xiaoxuan and Siegle, Joshua H. and Olsen, Shawn R. and Koch, Christof and Mihalas, Stefan and Arkhipov, Anton},
  year = {2020},
  month = may,
  journal = {Neuron},
  volume = {106},
  number = {3},
  pages = {388-403.e18},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.01.040},
  abstract = {Structural rules underlying functional properties of~cortical circuits are poorly understood. To explore these rules systematically, we integrated information from extensive literature curation and large-scale experimental surveys into a data-driven, biologically realistic simulation of the awake mouse primary visual cortex. The model was constructed at two levels of granularity, using either biophysically detailed or point neurons. Both variants have identical network connectivity and were compared to each other and to experimental recordings of visual-driven neural activity. While tuning these networks to recapitulate experimental data, we identified rules governing cell-class-specific connectivity and synaptic strengths. These structural constraints constitute hypotheses that can be tested experimentally. Despite their distinct single-cell abstraction, both spatially extended and point models perform similarly at the level of firing rate distributions for the questions we investigated. All data and models are freely available as a resource for the community.},
  langid = {english}
}

@article{bittnerInterrogatingTheoretical2021,
  title = {Interrogating Theoretical Models of Neural Computation with Emergent Property Inference},
  author = {Bittner, Sean R and Palmigiano, Agostina and Piet, Alex T and Duan, Chunyu A and Brody, Carlos D and Miller, Kenneth D and Cunningham, John},
  editor = {Huguenard, John R and O'Leary, Timothy and Goldman, Mark S},
  year = {2021},
  month = jul,
  journal = {eLife},
  volume = {10},
  pages = {e56265},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.56265},
  abstract = {A cornerstone of theoretical neuroscience is the circuit model: a system of equations that captures a hypothesized neural mechanism. Such models are valuable when they give rise to an experimentally observed phenomenon -- whether behavioral or a pattern of neural activity -- and thus can offer insights into neural computation. The operation of these circuits, like all models, critically depends on the choice of model parameters. A key step is then to identify the model parameters consistent with observed phenomena: to solve the inverse problem. In this work, we present a novel technique, emergent property inference (EPI), that brings the modern probabilistic modeling toolkit to theoretical neuroscience. When theorizing circuit models, theoreticians predominantly focus on reproducing computational properties rather than a particular dataset. Our method uses deep neural networks to learn parameter distributions with these computational properties. This methodology is introduced through a motivational example of parameter inference in the stomatogastric ganglion. EPI is then shown to allow precise control over the behavior of inferred parameters and to scale in parameter dimension better than alternative techniques. In the remainder of this work, we present novel theoretical findings in models of primary visual cortex and superior colliculus, which were gained through the examination of complex parametric structure captured by EPI. Beyond its scientific contribution, this work illustrates the variety of analyses possible once deep learning is harnessed towards solving theoretical inverse problems.},
  keywords = {circuit models,deep learning,theoretical neuroscience},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Bittner et al_2021_Interrogating theoretical models of neural computation with emergent property.pdf}
}

@misc{bonhemeHowVariational2022,
  title = {How Do {{Variational Autoencoders Learn}}? {{Insights}} from {{Representational Similarity}}},
  shorttitle = {How Do {{Variational Autoencoders Learn}}?},
  author = {Bonheme, Lisa and Grzes, Marek},
  year = {2022},
  month = may,
  number = {arXiv:2205.08399},
  eprint = {2205.08399},
  eprinttype = {arxiv},
  primaryclass = {cs},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2205.08399},
  abstract = {The ability of Variational Autoencoders (VAEs) to learn disentangled representations has made them popular for practical applications. However, their behaviour is not yet fully understood. For example, the questions of when they can provide disentangled representations, or suffer from posterior collapse are still areas of active research. Despite this, there are no layerwise comparisons of the representations learned by VAEs, which would further our understanding of these models. In this paper, we thus look into the internal behaviour of VAEs using representational similarity techniques. Specifically, using the CKA and Procrustes similarities, we found that the encoders' representations are learned long before the decoders', and this behaviour is independent of hyperparameters, learning objectives, and datasets. Moreover, the encoders' representations up to the mean and variance layers are similar across hyperparameters and learning objectives.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,G.3,I.2.6}
}

@article{bretteCodingRelevant2019,
  title = {Is Coding a Relevant Metaphor for the Brain?},
  author = {Brette, Romain},
  year = {2019},
  journal = {Behavioral and Brain Sciences},
  volume = {42},
  publisher = {{Cambridge University Press}},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X19000049},
  abstract = {``Neural coding'' is a popular metaphor in neuroscience, where objective properties of the world are communicated to the brain in the form of spikes. Here I argue that this metaphor is often inappropriate and misleading. First, when neurons are said to encode experimental parameters, the neural code depends on experimental details that are not carried by the coding variable (e.g., the spike count). Thus, the representational power of neural codes is much more limited than generally implied. Second, neural codes carry information only by reference to things with known meaning. In contrast, perceptual systems must build information from relations between sensory signals and actions, forming an internal model. Neural codes are inadequate for this purpose because they are unstructured and therefore unable to represent relations. Third, coding variables are observables tied to the temporality of experiments, whereas spikes are timed actions that mediate coupling in a distributed dynamical system. The coding metaphor tries to fit the dynamic, circular, and distributed causal structure of the brain into a linear chain of transformations between observables, but the two causal structures are incongruent. I conclude that the neural coding metaphor cannot provide a valid basis for theories of brain function, because it is incompatible with both the causal structure of the brain and the representational requirements of cognition.},
  langid = {english},
  keywords = {action,information,neural coding,perception,sensorimotor}
}

@article{brettePhilosophySpike2015,
  title = {Philosophy of the {{Spike}}: {{Rate-Based}} vs. {{Spike-Based Theories}} of the {{Brain}}},
  shorttitle = {Philosophy of the {{Spike}}},
  author = {Brette, Romain},
  year = {2015},
  journal = {Frontiers in Systems Neuroscience},
  volume = {9},
  pages = {151},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00151},
  abstract = {Does the brain use a firing rate code or a spike timing code? Considering this controversial question from an epistemological perspective, I argue that progress has been hampered by its problematic phrasing. It takes the perspective of an external observer looking at whether those two observables vary with stimuli, and thereby misses the relevant question: which one has a causal role in neural activity? When rephrased in a more meaningful way, the rate-based view appears as an ad hoc methodological postulate, one that is practical but with virtually no empirical or theoretical support.}
}

@article{brownWhyStudy2019,
  title = {Why {{Study}} the {{History}} of {{Neuroscience}}?},
  author = {Brown, Richard E.},
  year = {2019},
  journal = {Frontiers in Behavioral Neuroscience},
  volume = {13},
  pages = {82},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2019.00082},
  abstract = {The history of neuroscience is the memory of the discipline and this memory depends on the study of the present traces of the past; the things left behind: artifacts, equipment, written documents, data books, photographs, memoirs, etc. History, in all of its definitions, is an integral part of neuroscience and I have used examples from the literature and my personal experience to illustrate the importance of the different aspects of history in neuroscience. Each time we talk about the brain, do an experiment, or write a research article, we are involved in history. Each published experiment becomes a historical document; it relies on past research (the ``Introduction'' section), procedures developed in the past (``Methods'' section) and as soon as new data are published, they become history and become embedded into the history of the discipline (``Discussion'' section). In order to be transparent and able to be replicated, each experiment requires its own historical archive. Studying history means researching books, documents and objects in libraries, archives, and museums. It means looking at data books, letters and memos, talking to scientists, and reading biographies and autobiographies. History can be made relevant by integrating historical documents into classes and by using historical websites. Finally, conducting historical research can be interesting, entertaining, and can lead to travel to out-of-the-way and exotic places and meeting interesting people.},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Brown_2019_Why Study the History of Neuroscience.pdf}
}

@article{cadwellElectrophysiologicalTranscriptomic2016,
  title = {Electrophysiological, Transcriptomic and Morphologic Profiling of Single Neurons Using {{Patch-seq}}},
  author = {Cadwell, Cathryn R. and Palasantza, Athanasia and Jiang, Xiaolong and Berens, Philipp and Deng, Qiaolin and Yilmaz, Marlene and Reimer, Jacob and Shen, Shan and Bethge, Matthias and Tolias, Kimberley F. and Sandberg, Rickard and Tolias, Andreas S.},
  year = {2016},
  month = feb,
  journal = {Nat Biotechnol},
  volume = {34},
  number = {2},
  pages = {199--203},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.3445},
  abstract = {Patch-seq reveals new neuronal subtypes by combining electrophysiological and RNA-seq data on single neurons in situ.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Neuronal physiology;RNA sequencing Subject\_term\_id: neuronal-physiology;rna-sequencing},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Cadwell et al_2016_Electrophysiological, transcriptomic and morphologic profiling of single.pdf}
}

@article{cardinMesoscopicImaging2020,
  title = {Mesoscopic {{Imaging}}: {{Shining}} a {{Wide Light}} on {{Large-Scale Neural Dynamics}}},
  shorttitle = {Mesoscopic {{Imaging}}},
  author = {Cardin, Jessica A. and Crair, Michael C. and Higley, Michael J.},
  year = {2020},
  month = oct,
  journal = {Neuron},
  volume = {108},
  number = {1},
  pages = {33--43},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.09.031},
  abstract = {Optical imaging has revolutionized our ability to monitor brain activity, spanning spatial scales from synapses to cells to circuits. Here, we summarize the rapid development and application of mesoscopic imaging, a widefield fluorescence-based approach that balances high spatiotemporal resolution with extraordinarily large fields of view. By leveraging the continued expansion of fluorescent reporters for neuronal activity and novel strategies for indicator expression, mesoscopic analysis enables measurement and correlation of network dynamics with behavioral state and task performance. Moreover, the combination of widefield imaging with cellular resolution methods such as two-photon microscopy and electrophysiology is bridging boundaries between cellular and network analyses. Overall, mesoscopic imaging provides a powerful option in the optical toolbox for investigation of brain function.},
  langid = {english}
}

@article{cavanaghDiversityIntrinsic2020,
  title = {A {{Diversity}} of {{Intrinsic Timescales Underlie Neural Computations}}},
  author = {Cavanagh, Sean E. and Hunt, Laurence T. and Kennerley, Steven W.},
  year = {2020},
  journal = {Frontiers in Neural Circuits},
  volume = {14},
  pages = {81},
  issn = {1662-5110},
  doi = {10.3389/fncir.2020.615626},
  abstract = {Neural processing occurs across a range of temporal scales. To facilitate this, the brain uses fast-changing representations reflecting momentary sensory input alongside more temporally extended representations, which integrate across both short and long temporal windows. The temporal flexibility of these representations allows animals to behave adaptively. Short temporal windows facilitate adaptive responding in dynamic environments, while longer temporal windows promote the gradual integration of information across time. In the cognitive and motor domains, the brain sets overarching goals to be achieved within a long temporal window, which must be broken down into sequences of actions and precise movement control processed across much shorter temporal windows. Previous human neuroimaging studies and large-scale artificial network models have ascribed different processing timescales to different cortical regions, linking this to each region's position in an anatomical hierarchy determined by patterns of inter-regional connectivity. However, even within cortical regions, there is variability in responses when studied with single-neuron electrophysiology. Here, we review a series of recent electrophysiology experiments that demonstrate the heterogeneity of temporal receptive fields at the level of single neurons within a cortical region. This heterogeneity appears functionally relevant for the computations that neurons perform during decision-making and working memory. We consider anatomical and biophysical mechanisms that may give rise to a heterogeneity of timescales, including recurrent connectivity, cortical layer distribution, and neurotransmitter receptor expression. Finally, we reflect on the computational relevance of each brain region possessing a heterogeneity of neuronal timescales. We argue that this architecture is of particular importance for sensory, motor, and cognitive computations.}
}

@article{chungNeuralPopulation2021,
  title = {Neural Population Geometry: {{An}} Approach for Understanding Biological and Artificial Neural Networks},
  shorttitle = {Neural Population Geometry},
  author = {Chung, SueYeon and Abbott, L. F.},
  year = {2021},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  volume = {70},
  eprint = {2104.07059},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  pages = {137--144},
  issn = {09594388},
  doi = {10.1016/j.conb.2021.10.010},
  abstract = {Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, populations and behavior.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Chung_Abbott_2021_Neural population geometry.pdf}
}

@article{clarkeExecutableCancer2020,
  title = {Executable Cancer Models: Successes and Challenges},
  shorttitle = {Executable Cancer Models},
  author = {Clarke, Matthew A. and Fisher, Jasmin},
  year = {2020},
  month = jun,
  journal = {Nat Rev Cancer},
  volume = {20},
  number = {6},
  pages = {343--354},
  publisher = {{Nature Publishing Group}},
  issn = {1474-1768},
  doi = {10.1038/s41568-020-0258-x},
  abstract = {Making decisions on how best to treat cancer patients requires the integration of different data sets, including genomic profiles, tumour histopathology, radiological images, proteomic analysis and more. This wealth of biological information calls for novel strategies to integrate such information in a meaningful, predictive and experimentally verifiable way. In this Perspective we explain how executable computational models meet this need. Such models provide a means for comprehensive data integration, can be experimentally validated, are readily interpreted both biologically and clinically, and have the potential to predict effective therapies for different cancer types and subtypes. We explain what executable models are and how they can be used to represent the dynamic biological behaviours inherent in cancer, and demonstrate how such models, when coupled with automated reasoning, facilitate our understanding of the mechanisms by which oncogenic signalling pathways regulate tumours. We explore how executable models have impacted the field of cancer research and argue that extending them to represent a tumour in a specific patient (that is, an avatar) will pave the way for improved personalized treatments and precision medicine. Finally, we highlight some of the ongoing challenges in developing executable models and stress that effective cross-disciplinary efforts are key to forward progress in the field.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Cancer models;Computer modelling;Mathematics and computing Subject\_term\_id: cancer-models;computer-modelling;mathematics-and-computing},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroProfiles/PhD/Data/storage/43VVWYNK/Clarke_Fisher_2020_Executable cancer models.pdf}
}

@article{coutantClosedloopCycles2019,
  title = {Closed-Loop Cycles of Experiment Design, Execution, and Learning Accelerate Systems Biology Model Development in Yeast},
  author = {Coutant, Anthony and Roper, Katherine and {Trejo-Banos}, Daniel and Bouthinon, Dominique and Carpenter, Martin and Grzebyta, Jacek and Santini, Guillaume and Soldano, Henry and Elati, Mohamed and Ramon, Jan and Rouveirol, Celine and Soldatova, Larisa N. and King, Ross D.},
  year = {2019},
  month = sep,
  journal = {PNAS},
  volume = {116},
  number = {36},
  pages = {18142--18147},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1900548116},
  abstract = {One of the most challenging tasks in modern science is the development of systems biology models: Existing models are often very complex but generally have low predictive performance. The construction of high-fidelity models will require hundreds/thousands of cycles of model improvement, yet few current systems biology research studies complete even a single cycle. We combined multiple software tools with integrated laboratory robotics to execute three cycles of model improvement of the prototypical eukaryotic cellular transformation, the yeast (Saccharomyces cerevisiae) diauxic shift. In the first cycle, a model outperforming the best previous diauxic shift model was developed using bioinformatic and systems biology tools. In the second cycle, the model was further improved using automatically planned experiments. In the third cycle, hypothesis-led experiments improved the model to a greater extent than achieved using high-throughput experiments. All of the experiments were formalized and communicated to a cloud laboratory automation system (Eve) for automatic execution, and the results stored on the semantic web for reuse. The final model adds a substantial amount of knowledge about the yeast diauxic shift: 92 genes (+45\%), and 1,048 interactions (+147\%). This knowledge is also relevant to understanding cancer, the immune system, and aging. We conclude that systems biology software tools can be combined and integrated with laboratory robots in closed-loop cycles.},
  chapter = {Biological Sciences},
  copyright = {Copyright \textcopyright{} 2019 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
  langid = {english},
  pmid = {31420515},
  keywords = {artificial intelligence,diauxic shift,machine learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroProfiles/PhD/Data/storage/APY2B8YD/Coutant et al_2019_Closed-loop cycles of experiment design, execution, and learning accelerate.pdf}
}

@inproceedings{dapelloNeuralPopulation2021,
  title = {Neural {{Population Geometry Reveals}} the {{Role}} of {{Stochasticity}} in {{Robust Perception}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Dapello, Joel and Feather, Jenelle and Le, Hang and Marques, Tiago and Cox, David Daniel and Mcdermott, Josh and DiCarlo, James J. and Chung, SueYeon},
  year = {2021},
  month = may,
  abstract = {Adversarially trained networks and biologically inspired stochastic networks in both visual and auditory domains demonstrate distinct mechanisms for robust perception as revealed by neural...},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Dapello et al_2021_Neural Population Geometry Reveals the Role of Stochasticity in Robust.pdf}
}

@article{daviesAdvancingNeuromorphic2021,
  title = {Advancing {{Neuromorphic Computing With Loihi}}: {{A Survey}} of {{Results}} and {{Outlook}}},
  shorttitle = {Advancing {{Neuromorphic Computing With Loihi}}},
  author = {Davies, Mike and Wild, Andreas and Orchard, Garrick and Sandamirskaya, Yulia and Guerra, Gabriel A. Fonseca and Joshi, Prasad and Plank, Philipp and Risbud, Sumedh R.},
  year = {2021},
  month = may,
  journal = {Proceedings of the IEEE},
  volume = {109},
  number = {5},
  pages = {911--934},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2021.3067593},
  abstract = {Deep artificial neural networks apply principles of the brain's information processing that led to breakthroughs in machine learning spanning many problem domains. Neuromorphic computing aims to take this a step further to chips more directly inspired by the form and function of biological neural circuits, so they can process new knowledge, adapt, behave, and learn in real time at low power levels. Despite several decades of research, until recently, very few published results have shown that today's neuromorphic chips can demonstrate quantitative computational value. This is now changing with the advent of Intel's Loihi, a neuromorphic research processor designed to support a broad range of spiking neural networks with sufficient scale, performance, and features to deliver competitive results compared to state-of-the-art contemporary computing architectures. This survey reviews results that are obtained to date with Loihi across the major algorithmic domains under study, including deep learning approaches and novel approaches that aim to more directly harness the key features of spike-based neuromorphic hardware. While conventional feedforward deep neural networks show modest if any benefit on Loihi, more brain-inspired networks using recurrence, precise spike-timing relationships, synaptic plasticity, stochasticity, and sparsity perform certain computation with orders of magnitude lower latency and energy compared to state-of-the-art conventional approaches. These compelling neuromorphic networks solve a diverse range of problems representative of brain-like computation, such as event-based data processing, adaptive control, constrained optimization, sparse feature regression, and graph search.},
  keywords = {Biological neural networks,Brain modeling,Computational modeling,Computer architecture,Deep learning,neural network hardware,Neural networks,Neuromorphic engineering,neuromorphics,Neurons},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Davies et al_2021_Advancing Neuromorphic Computing With Loihi.pdf}
}

@misc{DeepLearning2021,
  title = {Deep {{Learning}}'s {{Diminishing Returns}}},
  year = {2021},
  month = sep,
  journal = {IEEE Spectrum},
  abstract = {The cost of improvement is becoming unsustainable},
  howpublished = {https://spectrum.ieee.org/deep-learning-computational-cost},
  langid = {english}
}

@misc{dingGroundingRepresentation2021,
  title = {Grounding {{Representation Similarity}} with {{Statistical Testing}}},
  author = {Ding, Frances and Denain, Jean-Stanislas and Steinhardt, Jacob},
  year = {2021},
  month = nov,
  number = {arXiv:2108.01661},
  eprint = {2108.01661},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2108.01661},
  abstract = {To understand neural network behavior, recent works quantitatively compare different networks' learned representations using canonical correlation analysis (CCA), centered kernel alignment (CKA), and other dissimilarity measures. Unfortunately, these widely used measures often disagree on fundamental observations, such as whether deep networks differing only in random initialization learn similar representations. These disagreements raise the question: which, if any, of these dissimilarity measures should we believe? We provide a framework to ground this question through a concrete test: measures should have sensitivity to changes that affect functional behavior, and specificity against changes that do not. We quantify this through a variety of functional behaviors including probing accuracy and robustness to distribution shift, and examine changes such as varying random initialization and deleting principal components. We find that current metrics exhibit different weaknesses, note that a classical baseline performs surprisingly well, and highlight settings where all metrics appear to fail, thus providing a challenge set for further improvement.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Ding et al_2021_Grounding Representation Similarity with Statistical Testing.pdf}
}

@article{dobsBrainlikeFunctional2022,
  title = {Brain-like Functional Specialization Emerges Spontaneously in Deep Neural Networks},
  author = {Dobs, Katharina and Martinez, Julio and Kell, Alexander J. E. and Kanwisher, Nancy},
  year = {2022},
  month = mar,
  journal = {Science Advances},
  volume = {8},
  number = {11},
  pages = {eabl8913},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abl8913}
}

@misc{dotyHeterogeneousCell2021,
  title = {Heterogeneous `Cell Types' Can Improve Performance of Deep Neural Networks},
  author = {Doty, Briar and Mihalas, Stefan and Arkhipov, Anton and Piet, Alex},
  year = {2021},
  month = jun,
  pages = {2021.06.21.449346},
  institution = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2021.06.21.449346},
  abstract = {Deep convolutional neural networks (CNNs) are powerful computational tools for a large variety of tasks (Goodfellow, 2016). Their architecture, composed of layers of repeated identical neural units, draws inspiration from visual neuroscience. However, biological circuits contain a myriad of additional details and complexity not translated to CNNs, including diverse neural cell types (Tasic, 2018). Many possible roles for neural cell types have been proposed, including: learning, stabilizing excitation and inhibition, and diverse normalization (Marblestone, 2016; Gouwens, 2019). Here we investigate whether neural cell types, instantiated as diverse activation functions in CNNs, can assist in the feed-forward computational abilities of neural circuits. Our heterogeneous cell type networks mix multiple activation functions within each activation layer. We assess the value of mixed activation functions by comparing image classification performance to that of homogeneous control networks with only one activation function per network. We observe that mixing activation functions can improve the image classification abilities of CNNs. Importantly, we find larger improvements when the activation functions are more diverse, and in more constrained networks. Our results suggest a feed-forward computational role for diverse cell types in biological circuits. Additionally, our results open new avenues for the development of more powerful CNNs.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english}
}

@article{dubreuilRolePopulation2022,
  title = {The Role of Population Structure in Computations through Neural Dynamics},
  author = {Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  year = {2022},
  month = jun,
  journal = {Nat Neurosci},
  volume = {25},
  number = {6},
  pages = {783--794},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01088-4},
  abstract = {Neural computations are envisioned as arising from either distinct function subpopulations or distributed collective dynamics. Dubreuil and Valente et al. examined recurrent neural networks trained on various cognitive tasks and found that a mixed-selective yet non-random subpopulation structure enabled flexible responding through gain-modulated latent dynamics.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Dynamical systems,Network models},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Dubreuil et al_2022_The role of population structure in computations through neural dynamics.pdf;/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Dubreuil et al_2022_The role of population structure in computations through neural dynamics2.pdf}
}

@article{eisensteinActiveMachine2020,
  title = {Active Machine Learning Helps Drug Hunters Tackle Biology},
  author = {Eisenstein, Michael},
  year = {2020},
  month = may,
  journal = {Nature Biotechnology},
  volume = {38},
  number = {5},
  pages = {512--514},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/s41587-020-0521-4},
  abstract = {A growing cadre of startups is pursuing iterative cycles of machine learning, wet-lab experimentation and human feedback to accelerate target drug discovery.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: News},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroProfiles/PhD/Data/storage/4V3IBY2R/Eisenstein_2020_Active machine learning helps drug hunters tackle biology.pdf}
}

@article{engelNewPerspectives2019,
  title = {New Perspectives on Dimensionality and Variability from Large-Scale Cortical Dynamics},
  author = {Engel, Tatiana A and Steinmetz, Nicholas A},
  year = {2019},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {58},
  pages = {181--190},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.09.003},
  abstract = {The neocortex is a multi-scale network, with intricate local circuitry interwoven into a global mesh of long-range connections. Neural activity propagates within this network on a wide range of temporal and spatial scales. At the micro scale, neurophysiological recordings reveal coordinated dynamics in local neural populations, which support behaviorally relevant computations. At the macro scale, neuroimaging modalities measure global activity fluctuations organized into spatiotemporal patterns across the entire brain. Here we review recent advances linking the local and global scales of cortical dynamics and their relationship to behavior. We argue that diverse experimental observations on the dimensionality and variability of neural activity can be reconciled by considering how activity propagates in space and time on multiple spatial scales.},
  langid = {english}
}

@article{ezerDataScience2019,
  title = {Data Science for the Scientific Life Cycle},
  author = {Ezer, Daphne and Whitaker, Kirstie},
  year = {2019},
  month = mar,
  journal = {eLife},
  volume = {8},
  pages = {e43979},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.43979},
  abstract = {Data science can be incorporated into every stage of a scientific study. Here we describe how data science can be used to generate hypotheses, to design experiments, to perform experiments, and to analyse data. We also present our vision for how data science techniques will be an integral part of the laboratory of the future.},
  keywords = {data science,experimental design,open science,reproducibility}
}

@article{finkelsteinAttractorDynamics2021a,
  title = {Attractor Dynamics Gate Cortical Information Flow during Decision-Making},
  author = {Finkelstein, Arseny and Fontolan, Lorenzo and Economo, Michael N. and Li, Nuo and Romani, Sandro and Svoboda, Karel},
  year = {2021},
  month = jun,
  journal = {Nat Neurosci},
  volume = {24},
  number = {6},
  pages = {843--850},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00840-6},
  abstract = {Decisions are held in memory until enacted, which makes them potentially vulnerable to distracting sensory input. Gating of information flow from sensory to motor areas could protect memory from interference during decision-making, but the underlying network mechanisms are not understood. Here, we trained mice to detect optogenetic stimulation of the somatosensory cortex, with a delay separating sensation and action. During the delay, distracting stimuli lost influence on behavior over time, even though distractor-evoked neural activity percolated through the cortex without attenuation. Instead, choice-encoding activity in the motor cortex became progressively less sensitive to the impact of distractors. Reverse engineering of neural networks trained to reproduce motor cortex activity revealed that the reduction in sensitivity to distractors was caused by a growing separation in the neural activity space between attractors that encode alternative decisions. Our results show that communication between brain regions can be gated via attractor dynamics, which control the degree of commitment to an action.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Decision;Network models Subject\_term\_id: decision;network-models}
}

@article{franclDeepNeural2022,
  title = {Deep Neural Network Models of Sound Localization Reveal How Perception Is Adapted to Real-World Environments},
  author = {Francl, Andrew and McDermott, Josh H.},
  year = {2022},
  month = jan,
  journal = {Nat Hum Behav},
  volume = {6},
  number = {1},
  pages = {111--133},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01244-z},
  abstract = {Mammals localize sounds using information from their two ears. Localization in real-world conditions is challenging, as echoes provide erroneous information and noises mask parts of target sounds. To better understand real-world localization, we equipped a deep neural network with human ears and trained it to localize sounds in a virtual environment. The resulting model localized accurately in realistic conditions with noise and reverberation. In simulated experiments, the model exhibited many features of human spatial hearing: sensitivity to monaural spectral cues and interaural time and level differences, integration across frequency, biases for sound onsets and limits on localization of concurrent sources. But when trained in unnatural environments without reverberation, noise or natural sounds, these performance characteristics deviated from those of humans. The results show how biological hearing is adapted to the challenges of real-world environments and illustrate how artificial neural networks can reveal the real-world constraints that shape perception.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Human behaviour,Sensory processing}
}

@article{galaConsistentCrossmodal2021,
  title = {Consistent Cross-Modal Identification of Cortical Neurons with Coupled Autoencoders},
  author = {Gala, Rohan and Budzillo, Agata and Baftizadeh, Fahimeh and Miller, Jeremy and Gouwens, Nathan and Arkhipov, Anton and Murphy, Gabe and Tasic, Bosiljka and Zeng, Hongkui and Hawrylycz, Michael and S{\"u}mb{\"u}l, Uygar},
  year = {2021},
  month = feb,
  journal = {Nat Comput Sci},
  volume = {1},
  number = {2},
  pages = {120--127},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00030-1},
  abstract = {Consistent identification of neurons in different experimental modalities is a key problem in neuroscience. Although methods to perform multimodal measurements in the same set of single neurons have become available, parsing complex relationships across different modalities to uncover neuronal identity is a growing challenge. Here we present an optimization framework to learn coordinated representations of multimodal data and apply it to a large multimodal dataset profiling mouse cortical interneurons. Our approach reveals strong alignment between transcriptomic and electrophysiological characterizations, enables accurate cross-modal data prediction, and identifies cell types that are consistent across modalities.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Cellular neuroscience;Computational neuroscience;Machine learning Subject\_term\_id: cellular-neuroscience;computational-neuroscience;machine-learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Gala et al_2021_Consistent cross-modal identification of cortical neurons with coupled.pdf}
}

@inproceedings{geirhosPartialSuccess2021,
  title = {Partial Success in Closing the Gap between Human and Machine Vision},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Geirhos, Robert and Narayanappa, Kantharaju and Mitzkus, Benjamin and Thieringer, Tizian and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
  year = {2021},
  month = may,
  abstract = {Data-rich models are closing the gap to human OOD distortion robustness and improve image-level consistency with human psychophysical data.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Geirhos et al_2021_Partial success in closing the gap between human and machine vision.pdf}
}

@misc{ghoshInvestigatingPower2022,
  title = {Investigating {{Power}} Laws in {{Deep Representation Learning}}},
  author = {Ghosh, Arna and Mondal, Arnab Kumar and Agrawal, Kumar Krishna and Richards, Blake},
  year = {2022},
  month = feb,
  number = {arXiv:2202.05808},
  eprint = {2202.05808},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2202.05808},
  abstract = {Representation learning that leverages large-scale labelled datasets, is central to recent progress in machine learning. Access to task relevant labels at scale is often scarce or expensive, motivating the need to learn from unlabelled datasets with self-supervised learning (SSL). Such large unlabelled datasets (with data augmentations) often provide a good coverage of the underlying input distribution. However evaluating the representations learned by SSL algorithms still requires task-specific labelled samples in the training pipeline. Additionally, the generalization of task-specific encoding is often sensitive to potential distribution shift. Inspired by recent advances in theoretical machine learning and vision neuroscience, we observe that the eigenspectrum of the empirical feature covariance matrix often follows a power law. For visual representations, we estimate the coefficient of the power law, \$\textbackslash alpha\$, across three key attributes which influence representation learning: learning objective (supervised, SimCLR, Barlow Twins and BYOL), network architecture (VGG, ResNet and Vision Transformer), and tasks (object and scene recognition). We observe that under mild conditions, proximity of \$\textbackslash alpha\$ to 1, is strongly correlated to the downstream generalization performance. Furthermore, \$\textbackslash alpha \textbackslash approx 1\$ is a strong indicator of robustness to label noise during fine-tuning. Notably, \$\textbackslash alpha\$ is computable from the representations without knowledge of any labels, thereby offering a framework to evaluate the quality of representations in unlabelled datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition}
}

@article{gouwensClassificationElectrophysiological2019,
  title = {Classification of Electrophysiological and Morphological Neuron Types in the Mouse Visual Cortex},
  author = {Gouwens, Nathan W. and Sorensen, Staci A. and Berg, Jim and Lee, Changkyu and Jarsky, Tim and Ting, Jonathan and Sunkin, Susan M. and Feng, David and Anastassiou, Costas A. and Barkan, Eliza and Bickley, Kris and Blesie, Nicole and Braun, Thomas and Brouner, Krissy and Budzillo, Agata and Caldejon, Shiella and Casper, Tamara and Castelli, Dan and Chong, Peter and Crichton, Kirsten and Cuhaciyan, Christine and Daigle, Tanya L. and Dalley, Rachel and Dee, Nick and Desta, Tsega and Ding, Song-Lin and Dingman, Samuel and Doperalski, Alyse and Dotson, Nadezhda and Egdorf, Tom and Fisher, Michael and {de Frates}, Rebecca A. and Garren, Emma and Garwood, Marissa and Gary, Amanda and Gaudreault, Nathalie and Godfrey, Keith and Gorham, Melissa and Gu, Hong and Habel, Caroline and Hadley, Kristen and Harrington, James and Harris, Julie A. and Henry, Alex and Hill, DiJon and Josephsen, Sam and Kebede, Sara and Kim, Lisa and Kroll, Matthew and Lee, Brian and Lemon, Tracy and Link, Katherine E. and Liu, Xiaoxiao and Long, Brian and Mann, Rusty and McGraw, Medea and Mihalas, Stefan and Mukora, Alice and Murphy, Gabe J. and Ng, Lindsay and Ngo, Kiet and Nguyen, Thuc Nghi and Nicovich, Philip R. and Oldre, Aaron and Park, Daniel and Parry, Sheana and Perkins, Jed and Potekhina, Lydia and Reid, David and Robertson, Miranda and Sandman, David and Schroedter, Martin and Slaughterbeck, Cliff and {Soler-Llavina}, Gilberto and Sulc, Josef and Szafer, Aaron and Tasic, Bosiljka and Taskin, Naz and Teeter, Corinne and Thatra, Nivretta and Tung, Herman and Wakeman, Wayne and Williams, Grace and Young, Rob and Zhou, Zhi and Farrell, Colin and Peng, Hanchuan and Hawrylycz, Michael J. and Lein, Ed and Ng, Lydia and Arkhipov, Anton and Bernard, Amy and Phillips, John W. and Zeng, Hongkui and Koch, Christof},
  year = {2019},
  month = jul,
  journal = {Nat Neurosci},
  volume = {22},
  number = {7},
  pages = {1182--1195},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0417-0},
  abstract = {Understanding the diversity of cell types in the brain has been an enduring challenge and requires detailed characterization of individual neurons in multiple dimensions. To systematically profile morpho-electric properties of mammalian neurons, we established a single-cell characterization pipeline using standardized patch-clamp recordings in brain slices and biocytin-based neuronal reconstructions. We built a publicly accessible online database, the Allen Cell Types Database, to display these datasets. Intrinsic physiological properties were measured from 1,938 neurons from the adult laboratory mouse visual cortex, morphological properties were measured from 461 reconstructed neurons, and 452 neurons had both measurements available. Quantitative features were used to classify neurons into distinct types using unsupervised methods. We established a taxonomy of morphologically and electrophysiologically defined cell types for this region of the cortex, with 17 electrophysiological types, 38 morphological types and 46 morpho-electric types. There was good correspondence with previously defined transcriptomic cell types and subclasses using the same transgenic mouse lines.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Cellular neuroscience;Striate cortex Subject\_term\_id: cellular-neuroscience;striate-cortex}
}

@article{gouwensIntegratedMorphoelectric2020,
  title = {Integrated {{Morphoelectric}} and {{Transcriptomic Classification}} of {{Cortical GABAergic Cells}}},
  author = {Gouwens, Nathan W. and Sorensen, Staci A. and Baftizadeh, Fahimeh and Budzillo, Agata and Lee, Brian R. and Jarsky, Tim and Alfiler, Lauren and Baker, Katherine and Barkan, Eliza and Berry, Kyla and Bertagnolli, Darren and Bickley, Kris and Bomben, Jasmine and Braun, Thomas and Brouner, Krissy and Casper, Tamara and Crichton, Kirsten and Daigle, Tanya L. and Dalley, Rachel and {de Frates}, Rebecca A. and Dee, Nick and Desta, Tsega and Lee, Samuel Dingman and Dotson, Nadezhda and Egdorf, Tom and Ellingwood, Lauren and Enstrom, Rachel and Esposito, Luke and Farrell, Colin and Feng, David and Fong, Olivia and Gala, Rohan and Gamlin, Clare and Gary, Amanda and Glandon, Alexandra and Goldy, Jeff and Gorham, Melissa and Graybuck, Lucas and Gu, Hong and Hadley, Kristen and Hawrylycz, Michael J. and Henry, Alex M. and Hill, DiJon and Hupp, Madie and Kebede, Sara and Kim, Tae Kyung and Kim, Lisa and Kroll, Matthew and Lee, Changkyu and Link, Katherine E. and Mallory, Matthew and Mann, Rusty and Maxwell, Michelle and McGraw, Medea and McMillen, Delissa and Mukora, Alice and Ng, Lindsay and Ng, Lydia and Ngo, Kiet and Nicovich, Philip R. and Oldre, Aaron and Park, Daniel and Peng, Hanchuan and Penn, Osnat and Pham, Thanh and Pom, Alice and Popovi{\'c}, Zoran and Potekhina, Lydia and Rajanbabu, Ramkumar and Ransford, Shea and Reid, David and Rimorin, Christine and Robertson, Miranda and Ronellenfitch, Kara and Ruiz, Augustin and Sandman, David and Smith, Kimberly and Sulc, Josef and Sunkin, Susan M. and Szafer, Aaron and Tieu, Michael and Torkelson, Amy and Trinh, Jessica and Tung, Herman and Wakeman, Wayne and Ward, Katelyn and Williams, Grace and Zhou, Zhi and Ting, Jonathan T. and Arkhipov, Anton and S{\"u}mb{\"u}l, Uygar and Lein, Ed S. and Koch, Christof and Yao, Zizhen and Tasic, Bosiljka and Berg, Jim and Murphy, Gabe J. and Zeng, Hongkui},
  year = {2020},
  month = nov,
  journal = {Cell},
  volume = {183},
  number = {4},
  pages = {935-953.e19},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2020.09.057},
  abstract = {Neurons are frequently classified into distinct types on the basis of structural, physiological, or genetic attributes. To better constrain the definition of neuronal cell types, we characterized the transcriptomes and intrinsic physiological properties of over 4,200 mouse visual cortical GABAergic interneurons and reconstructed the local morphologies of 517 of those neurons. We find that most transcriptomic types (t-types) occupy specific laminar positions within visual cortex, and, for most types, the cells mapping to a t-type exhibit consistent electrophysiological and morphological properties. These properties display both discrete and continuous variation among t-types. Through multimodal integrated analysis, we define 28 met-types that have congruent morphological, electrophysiological, and transcriptomic properties and robust mutual predictability. We identify layer-specific axon innervation pattern as a defining feature distinguishing different met-types. These met-types represent a unified definition of cortical GABAergic interneuron types, providing a systematic framework to capture existing knowledge and bridge future analyses across different modalities.},
  langid = {english},
  keywords = {GABAergic interneurons,multimodal,neuronal cell type,parvalbumin,Patch-seq,somatostatin,taxonomy,transcriptomics,visual cortex}
}

@article{graumannSpatiotemporalNeural2022,
  title = {The Spatiotemporal Neural Dynamics of Object Location Representations in the Human Brain},
  author = {Graumann, Monika and Ciuffi, Caterina and Dwivedi, Kshitij and Roig, Gemma and Cichy, Radoslaw M.},
  year = {2022},
  month = feb,
  journal = {Nat Hum Behav},
  pages = {1--16},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01302-0},
  abstract = {To interact with objects in complex environments, we must know what they are and where they are in spite of challenging viewing conditions. Here, we investigated where, how and when representations of object location and category emerge in the human brain when objects appear on cluttered natural scene images using a combination of functional magnetic resonance imaging, electroencephalography and computational models. We found location representations to emerge along the ventral visual stream towards lateral occipital complex, mirrored by gradual emergence in deep neural networks. Time-resolved analysis suggested that computing object location representations involves recurrent processing in high-level visual cortex. Object category representations also emerged gradually along the ventral visual stream, with evidence for recurrent computations. These results resolve the spatiotemporal dynamics of the ventral visual stream that give rise to representations of where and what objects are present in a scene under challenging viewing conditions.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Extrastriate cortex,Learning algorithms,Neural decoding,Object vision,Perception},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Graumann et al_2022_The spatiotemporal neural dynamics of object location representations in the.pdf}
}

@article{hahnPortraitsCommunication2019,
  title = {Portraits of Communication in Neuronal Networks},
  author = {Hahn, Gerald and {Ponce-Alvarez}, Adrian and Deco, Gustavo and Aertsen, Ad and Kumar, Arvind},
  year = {2019},
  month = feb,
  journal = {Nat Rev Neurosci},
  volume = {20},
  number = {2},
  pages = {117--127},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-018-0094-0},
  abstract = {The brain is organized as a network of highly specialized networks of spiking neurons. To exploit such a modular architecture for computation, the brain has to be able to regulate the flow of spiking activity between these specialized networks. In this Opinion article, we review various prominent mechanisms that may underlie communication between neuronal networks. We show that communication between neuronal networks can be understood as trajectories in a two-dimensional state space, spanned by the properties of the input. Thus, we propose a common framework to understand neuronal communication mediated by seemingly different mechanisms. We also suggest that the nesting of slow (for example, alpha-band and theta-band) oscillations and fast (gamma-band) oscillations can serve as an important control mechanism that allows or prevents spiking signals to be routed between specific networks. We argue that slow oscillations can modulate the time required to establish network resonance or entrainment and, thereby, regulate communication between neuronal networks.},
  copyright = {2018 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Network models;Neural circuits Subject\_term\_id: network-models;neural-circuit}
}

@article{hanLogicSinglecell2018,
  title = {The Logic of Single-Cell Projections from Visual Cortex},
  author = {Han, Yunyun and Kebschull, Justus M. and Campbell, Robert A. A. and Cowan, Devon and Imhof, Fabia and Zador, Anthony M. and {Mrsic-Flogel}, Thomas D.},
  year = {2018},
  month = apr,
  journal = {Nature},
  volume = {556},
  number = {7699},
  pages = {51--56},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature26159},
  abstract = {Neocortical areas communicate through extensive axonal projections, but the logic of information transfer remains poorly understood, because the projections of individual neurons have not been systematically characterized. It is not known whether individual neurons send projections only to single cortical areas or distribute signals across multiple targets. Here we determine the projection patterns of 591 individual neurons in the mouse primary visual cortex using whole-brain fluorescence-based axonal tracing and high-throughput DNA sequencing of genetically barcoded neurons (MAPseq). Projections were highly diverse and divergent, collectively targeting at least 18 cortical and subcortical areas. Most neurons targeted multiple cortical areas, often in non-random combinations, suggesting that sub-classes of intracortical projection neurons exist. Our results indicate that the dominant mode of intracortical information transfer is not based on `one neuron\textendash one target area' mapping. Instead, signals carried by individual cortical neurons are shared across subsets of target areas, and thus concurrently contribute to multiple functional pathways.},
  copyright = {2018 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Extrastriate cortex;Neural circuits;Sensory processing Subject\_term\_id: extrastriate-cortex;neural-circuit;sensory-processing}
}

@article{harrisHierarchicalOrganization2019,
  title = {Hierarchical Organization of Cortical and Thalamic Connectivity},
  author = {Harris, Julie A. and Mihalas, Stefan and Hirokawa, Karla E. and Whitesell, Jennifer D. and Choi, Hannah and Bernard, Amy and Bohn, Phillip and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Feiner, Aaron and Feng, David and Gaudreault, Nathalie and Gerfen, Charles R. and Graddis, Nile and Groblewski, Peter A. and Henry, Alex M. and Ho, Anh and Howard, Robert and Knox, Joseph E. and Kuan, Leonard and Kuang, Xiuli and Lecoq, Jerome and Lesnar, Phil and Li, Yaoyao and Luviano, Jennifer and McConoughey, Stephen and Mortrud, Marty T. and Naeemi, Maitham and Ng, Lydia and Oh, Seung Wook and Ouellette, Benjamin and Shen, Elise and Sorensen, Staci A. and Wakeman, Wayne and Wang, Quanxin and Wang, Yun and Williford, Ali and Phillips, John W. and Jones, Allan R. and Koch, Christof and Zeng, Hongkui},
  year = {2019},
  month = nov,
  journal = {Nature},
  volume = {575},
  number = {7781},
  pages = {195--202},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1716-z},
  abstract = {The mammalian cortex is a laminar structure containing many areas and cell types that are densely interconnected in complex ways, and for which generalizable principles of organization remain mostly unknown. Here we describe a major expansion of the Allen Mouse Brain Connectivity Atlas resource1, involving around a thousand new tracer experiments in the cortex and its main satellite structure, the thalamus. We used Cre driver lines (mice expressing Cre recombinase) to comprehensively and selectively label brain-wide connections by layer and class of projection neuron. Through observations of axon termination patterns, we have derived a set of generalized anatomical rules to describe corticocortical, thalamocortical and corticothalamic projections. We have built a model to assign connection patterns between areas as either feedforward or feedback, and generated testable predictions of hierarchical positions for individual cortical and thalamic areas and for cortical network modules. Our results show that cell-class-specific connections are organized in a shallow hierarchy within the mouse corticothalamic network.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Computational neuroscience;Neural circuits Subject\_term\_id: computational-neuroscience;neural-circuit},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Harris et al_2019_Hierarchical organization of cortical and thalamic connectivity.pdf}
}

@article{hassabisNeuroscienceInspiredArtificial2017,
  title = {Neuroscience-{{Inspired Artificial Intelligence}}},
  author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  year = {2017},
  month = jul,
  journal = {Neuron},
  volume = {95},
  number = {2},
  pages = {245--258},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.06.011},
  abstract = {The fields of neuroscience and artificial intelligence (AI) have a long and intertwined history. In more recent times, however, communication and collaboration between the two fields has become less commonplace. In this article, we argue that better understanding biological brains could play a vital role in building intelligent machines. We survey historical interactions between the AI and neuroscience fields and emphasize current advances in AI that have been inspired by the study of neural computation in humans and other animals. We conclude by highlighting shared themes that may be key for advancing future research in both fields.},
  langid = {english},
  keywords = {artificial intelligence,brain,cognition,learning,neural network},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Hassabis et al_2017_Neuroscience-Inspired Artificial Intelligence.pdf}
}

@article{hassonDirectFit2020,
  title = {Direct {{Fit}} to {{Nature}}: {{An Evolutionary Perspective}} on {{Biological}} and {{Artificial Neural Networks}}},
  shorttitle = {Direct {{Fit}} to {{Nature}}},
  author = {Hasson, Uri and Nastase, Samuel A. and Goldstein, Ariel},
  year = {2020},
  month = feb,
  journal = {Neuron},
  volume = {105},
  number = {3},
  pages = {416--434},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.12.002},
  abstract = {Evolution is a blind fitting process by which organisms become adapted to their environment. Does the brain use similar brute-force fitting processes to learn how to perceive and act upon the world? Recent advances in artificial neural networks have exposed the power of optimizing millions of synaptic weights over millions of observations to operate robustly in real-world contexts. These models do not learn simple, human-interpretable rules or representations of the world; rather, they use local computations to interpolate over task-relevant manifolds in a high-dimensional parameter space. Counterintuitively, similar to evolutionary processes, over-parameterized models can be simple and parsimonious, as they provide a versatile, robust solution for learning a diverse set of functions. This new family of direct-fit models present a radical challenge to many of the theoretical assumptions in psychology and neuroscience. At the same time, this shift in perspective establishes unexpected links with developmental and ecological psychology.},
  langid = {english},
  keywords = {evolution,experimental design,interpolation,learning,neural networks},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Hasson et al_2020_Direct Fit to Nature.pdf}
}

@article{hattoriContextdependentPersistency2022,
  title = {Context-Dependent Persistency as a Coding Mechanism for Robust and Widely Distributed Value Coding},
  author = {Hattori, Ryoma and Komiyama, Takaki},
  year = {2022},
  month = feb,
  journal = {Neuron},
  volume = {110},
  number = {3},
  pages = {502-515.e11},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.11.001},
  abstract = {Task-related information is widely distributed across the brain with different coding properties, such as persistency. We found in mice that coding persistency of action history and value was variable across areas, learning phases, and task context, with the highest persistency in the retrosplenial cortex of expert mice performing value-based decisions where history needs to be maintained across trials. Persistent coding also emerged in artificial networks trained to perform mouse-like reinforcement learning. Persistency allows temporally untangled value representations in neuronal manifolds where population activity exhibits cyclic trajectories that transition along the value axis after action outcomes, collectively forming cylindrical dynamics. Simulations indicated that untangled persistency facilitates robust value retrieval by downstream networks. Even leakage of persistently maintained value through non-specific connectivity could contribute to the brain-wide distributed value coding with different levels of persistency. These results reveal that context-dependent, untangled persistency facilitates reliable signal coding and its distribution across the brain.},
  langid = {english},
  keywords = {context dependent,deep learning,history coding,machine learning,manifold,persistent coding,recurrent neural network,reinforcement learning,retrosplenial cortex,value-based decision making}
}

@article{hennequinDynamicalRegime2018,
  title = {The {{Dynamical Regime}} of {{Sensory Cortex}}: {{Stable Dynamics}} around a {{Single Stimulus-Tuned Attractor Account}} for {{Patterns}} of {{Noise Variability}}},
  shorttitle = {The {{Dynamical Regime}} of {{Sensory Cortex}}},
  author = {Hennequin, Guillaume and Ahmadian, Yashar and Rubin, Daniel B. and Lengyel, M{\'a}t{\'e} and Miller, Kenneth D.},
  year = {2018},
  month = may,
  journal = {Neuron},
  volume = {98},
  number = {4},
  pages = {846-860.e5},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.04.017},
  abstract = {Correlated variability in cortical activity is ubiquitously quenched following stimulus onset, in a stimulus-dependent manner. These modulations have been attributed to circuit dynamics involving either multiple stable states (``attractors'') or chaotic activity. Here we show that a qualitatively different dynamical regime, involving fluctuations about a single, stimulus-driven attractor in a loosely balanced excitatory-inhibitory network (the stochastic ``stabilized supralinear network''), best explains these modulations. Given the supralinear input/output functions of cortical neurons, increased stimulus drive strengthens effective network connectivity. This shifts the balance from interactions that amplify~variability to suppressive inhibitory feedback, quenching correlated variability around more strongly driven steady states. Comparing to previously published and original data analyses, we show that this mechanism, unlike previous proposals, uniquely accounts for the spatial patterns and fast temporal dynamics of variability suppression. Specifying the cortical operating regime is key~to understanding the computations underlying perception.},
  langid = {english},
  keywords = {circuit dynamics,cortical variability,MT,noise correlations,theoretical neuroscience,V1,variability quenching}
}

@article{huangBRICseqBridges2020,
  title = {{{BRICseq Bridges Brain-wide Interregional Connectivity}} to {{Neural Activity}} and {{Gene Expression}} in {{Single Animals}}},
  author = {Huang, Longwen and Kebschull, Justus M. and F{\"u}rth, Daniel and Musall, Simon and Kaufman, Matthew T. and Churchland, Anne K. and Zador, Anthony M.},
  year = {2020},
  month = jul,
  journal = {Cell},
  volume = {182},
  number = {1},
  pages = {177-188.e27},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2020.05.029},
  abstract = {Comprehensive analysis of neuronal networks requires brain-wide measurement of connectivity, activity, and gene expression. Although high-throughput methods are available for mapping brain-wide activity and transcriptomes, comparable methods for mapping region-to-region connectivity remain slow and expensive because they require averaging across hundreds of brains. Here we describe BRICseq (brain-wide individual animal connectome sequencing), which leverages DNA barcoding and sequencing to map connectivity from single individuals in a few weeks and at low cost. Applying BRICseq to the mouse neocortex, we find that region-to-region connectivity provides a simple bridge relating transcriptome to activity: the spatial expression patterns of a few genes predict region-to-region connectivity, and connectivity predicts activity correlations. We also exploited BRICseq to map the mutant BTBR mouse brain, which lacks a corpus callosum, and recapitulated its known connectopathies. BRICseq allows individual laboratories to compare how age, sex, environment, genetics, and species affect neuronal wiring and to integrate these with functional activity and gene expression.},
  langid = {english},
  keywords = {BRICseq,connectome,high-throughput sequencing,MAPseq,mesoscale},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Huang et al_2020_BRICseq Bridges Brain-wide Interregional Connectivity to Neural Activity and.pdf}
}

@article{huthNaturalSpeech2016,
  title = {Natural Speech Reveals the Semantic Maps That Tile Human Cerebral Cortex},
  author = {Huth, Alexander G. and {de Heer}, Wendy A. and Griffiths, Thomas L. and Theunissen, Fr{\'e}d{\'e}ric E. and Gallant, Jack L.},
  year = {2016},
  month = apr,
  journal = {Nature},
  volume = {532},
  number = {7600},
  pages = {453--458},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature17637},
  abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the `semantic system'. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods\textemdash commonplace in studies of human neuroanatomy and functional connectivity\textemdash provide a powerful and efficient means for mapping functional representations in the brain.},
  copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Language,Neural encoding}
}

@article{inagakiDiscreteAttractor2019,
  title = {Discrete Attractor Dynamics Underlies Persistent Activity in the Frontal Cortex},
  author = {Inagaki, Hidehiko K. and Fontolan, Lorenzo and Romani, Sandro and Svoboda, Karel},
  year = {2019},
  month = feb,
  journal = {Nature},
  volume = {566},
  number = {7743},
  pages = {212--217},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-0919-7},
  abstract = {Short-term memories link events separated in time, such as past sensation and future actions. Short-term memories are correlated with slow neural dynamics, including selective persistent activity, which can be maintained over seconds. In a delayed response task that requires short-term memory, neurons in the mouse anterior lateral motor cortex (ALM) show persistent activity that instructs future actions. To determine the principles that underlie this persistent activity, here we combined intracellular and extracellular electrophysiology with optogenetic perturbations and network modelling. We show that during the delay epoch, the activity of ALM neurons moved towards discrete end points that correspond to specific movement directions. These end points were robust to transient shifts in ALM activity caused by optogenetic perturbations. Perturbations occasionally switched the population dynamics to the other end point, followed by incorrect actions. Our results show that discrete attractor dynamics underlie short-term memory related to motor planning.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Dynamical systems;Premotor cortex;Short-term memory Subject\_term\_id: dynamical-systems;premotor-cortex;short-term-memory}
}

@article{itoDiscoveringComputational2020,
  title = {Discovering the {{Computational Relevance}} of {{Brain Network Organization}}},
  author = {Ito, Takuya and Hearne, Luke and Mill, Ravi and Cocuzza, Carrisa and Cole, Michael W.},
  year = {2020},
  month = jan,
  journal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {1},
  pages = {25--38},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2019.10.005},
  abstract = {Understanding neurocognitive computations will require not just localizing cognitive information distributed throughout the brain but also determining how that information got there. We review recent advances in linking empirical and simulated brain network organization with cognitive information processing. Building on these advances, we offer a new framework for understanding the role of connectivity in cognition: network coding (encoding/decoding) models. These models utilize connectivity to specify the transfer of information via neural activity flow processes, successfully predicting the formation of cognitive representations in empirical neural data. The success of these models supports the possibility that localized neural functions mechanistically emerge (are computed) from distributed activity flow processes that are specified primarily by connectivity patterns.},
  langid = {english},
  keywords = {artificial intelligence,connectivity,connectome,machine learning,neural encoding/decoding,neural networks,representations}
}

@article{janesEngineeringDesign2017,
  title = {An Engineering Design Approach to Systems Biology},
  author = {Janes, Kevin A. and Chandran, Preethi L. and Ford, Roseanne M. and Lazzara, Matthew J. and Papin, Jason A. and Peirce, Shayn M. and Saucerman, Jeffrey J. and Lauffenburger, Douglas A.},
  year = {2017},
  month = jul,
  journal = {Integrative Biology},
  volume = {9},
  number = {7},
  pages = {574--583},
  issn = {1757-9708},
  doi = {10.1039/c7ib00014f},
  abstract = {Measuring and modeling the integrated behavior of biomolecular\textendash cellular networks is central to systems biology. Over several decades, systems biology has been shaped by quantitative biologists, physicists, mathematicians, and engineers in different ways. However, the basic and applied versions of systems biology are not typically distinguished, which blurs the separate aspirations of the field and its potential for real-world impact. Here, we articulate an engineering approach to systems biology, which applies educational philosophy, engineering design, and predictive models to solve contemporary problems in an age of biomedical Big Data. A concerted effort to train systems bioengineers will provide a versatile workforce capable of tackling the diverse challenges faced by the biotechnological and pharmaceutical sectors in a modern, information-dense economy.},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroProfiles/PhD/Data/storage/YJI6CKW2/Janes et al_2017_An engineering design approach to systems biology.pdf}
}

@inproceedings{keeleyIdentifyingSignal2020,
  title = {Identifying Signal and Noise Structure in Neural Population Activity with {{Gaussian}} Process Factor Models},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Keeley, Stephen and Aoi, Mikio and Yu, Yiyi and Smith, Spencer and Pillow, Jonathan W},
  year = {2020},
  volume = {33},
  pages = {13795--13805},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Neural datasets often contain measurements of neural activity across multiple trials of a repeated stimulus or behavior. An important problem in the analysis of such datasets is to characterize systematic aspects of neural activity that carry information about the repeated stimulus or behavior of interest, which can be considered signal'', and to separate them from the trial-to-trial fluctuations in activity that are not time-locked to the stimulus, which for purposes of such analyses can be considerednoise''. Gaussian Process factor models provide a powerful tool for identifying shared structure in high-dimensional neural data. However, they have not yet been adapted to the problem of characterizing signal and noise in multi-trial datasets. Here we address this shortcoming by proposing signal-noise'' Poisson-spiking Gaussian Process Factor Analysis (SNP-GPFA), a flexible latent variable model that resolves signal and noise latent structure in neural population spiking activity. To learn the parameters of our model, we introduce a Fourier-domain black box variational inference method that quickly identifies smooth latent structure. The resulting model reliably uncovers latent signal and trial-to-trial noise-related fluctuations in large-scale recordings. We use this model to show that in monkey V1, noise fluctuations perturb neural activity within a subspace orthogonal to signal activity, suggesting that trial-by-trial noise does not interfere with signal representations. Finally, we extend the model to capture statistical dependencies across brain regions in multi-region data. We show that in mouse visual cortex, models with shared noise across brain regions out-perform models with independent per-region noise.},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Keeley et al_2020_Identifying signal and noise structure in neural population activity with.pdf}
}

@article{kellerFeedbackGenerates2020,
  title = {Feedback Generates a Second Receptive Field in Neurons of the Visual Cortex},
  author = {Keller, Andreas J. and Roth, Morgane M. and Scanziani, Massimo},
  year = {2020},
  month = jun,
  journal = {Nature},
  volume = {582},
  number = {7813},
  pages = {545--549},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2319-4},
  abstract = {Animals sense the environment through pathways that link sensory organs to the brain. In the visual system, these feedforward pathways define the classical feedforward receptive field (ffRF), the area in space in which visual stimuli excite a neuron1. The visual system also uses visual context\textemdash the visual scene surrounding a stimulus\textemdash to predict the content of the stimulus2, and accordingly, neurons have been identified that are excited by stimuli outside their ffRF3\textendash 8. However, the mechanisms that generate excitation to stimuli outside the ffRF are unclear. Here we show that feedback projections onto excitatory neurons in the mouse primary visual cortex generate a second receptive field that is driven by stimuli outside the ffRF. The stimulation of this feedback receptive field (fbRF) elicits responses that are slower and are delayed in comparison with those resulting from the stimulation of the ffRF. These responses are preferentially reduced by anaesthesia and by silencing higher visual areas. Feedback inputs from higher visual areas have scattered receptive fields relative to their putative targets in the primary visual cortex, which enables the generation of the fbRF. Neurons with fbRFs are located in cortical layers that receive strong feedback projections and are absent in the main input layer, which is consistent with a laminar processing hierarchy. The observation that large, uniform stimuli\textemdash which cover both the fbRF and the ffRF\textemdash suppress these responses indicates that the fbRF and the ffRF are mutually antagonistic. Whereas somatostatin-expressing inhibitory neurons are driven by these large stimuli, inhibitory neurons that express parvalbumin and vasoactive intestinal peptide have mutually antagonistic fbRF and ffRF, similar to excitatory neurons. Feedback projections may therefore enable neurons to use context to estimate information that is missing from the ffRF and to report differences in stimulus features across visual space, regardless of whether excitation occurs inside or outside the ffRF. By complementing the ffRF, the fbRF that we identify here could contribute to predictive processing.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Neurophysiology;Visual system Subject\_term\_id: neurophysiology;visual-system}
}

@article{kepecsInterneuronCell2014,
  title = {Interneuron Cell Types Are Fit to Function},
  author = {Kepecs, Adam and Fishell, Gordon},
  year = {2014},
  month = jan,
  journal = {Nature},
  volume = {505},
  number = {7483},
  pages = {318--326},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature12983},
  abstract = {Understanding brain circuits begins with an appreciation of their component parts \textemdash{} the cells. Although GABAergic interneurons are a minority population within the brain, they are crucial for the control of inhibition. Determining the diversity of these interneurons has been a central goal of neurobiologists, but this amazing cell type has so far defied a generalized classification system. Interneuron complexity within the telencephalon could be simplified by viewing them as elaborations of a much more finite group of developmentally specified cardinal classes that become further specialized as they mature. Our perspective emphasizes that the ultimate goal is to dispense with classification criteria and directly define interneuron types by function.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Developmental biology;Neuroscience Subject\_term\_id: developmental-biology;neuroscience},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Kepecs_Fishell_2014_Interneuron cell types are fit to function.pdf}
}

@article{kietzmannRecurrenceRequired2019,
  title = {Recurrence Is Required to Capture the Representational Dynamics of the Human Visual System},
  author = {Kietzmann, Tim C. and Spoerer, Courtney J. and S{\"o}rensen, Lynn K. A. and Cichy, Radoslaw M. and Hauk, Olaf and Kriegeskorte, Nikolaus},
  year = {2019},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {43},
  pages = {21854--21863},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1905544116}
}

@article{kimRingAttractor2017,
  title = {Ring Attractor Dynamics in the {{Drosophila}} Central Brain},
  author = {Kim, Sung Soo and Rouault, Herv{\'e} and Druckmann, Shaul and Jayaraman, Vivek},
  year = {2017},
  month = may,
  journal = {Science},
  volume = {356},
  number = {6340},
  pages = {849--853},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aal4835}
}

@article{kimStrongInhibitory2021,
  title = {Strong Inhibitory Signaling Underlies Stable Temporal Dynamics and Working Memory in Spiking Neural Networks},
  author = {Kim, Robert and Sejnowski, Terrence J.},
  year = {2021},
  month = jan,
  journal = {Nat Neurosci},
  volume = {24},
  number = {1},
  pages = {129--139},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-00753-w},
  abstract = {By analyzing computational models and neural data from the primate prefrontal cortex, the authors show that inhibitory-to-inhibitory signaling is critical for the stable temporal dynamics required for performing working memory tasks.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Cortex;Network models;Neural circuits;Short-term memory;Working memory Subject\_term\_id: cortex;network-models;neural-circuit;short-term-memory;working-memory}
}

@article{kirchbergerEssentialRole2021,
  title = {The Essential Role of Recurrent Processing for Figure-Ground Perception in Mice},
  author = {Kirchberger, Lisa and Mukherjee, Sreedeep and Schnabel, Ulf H. and {van Beest}, Enny H. and Barsegyan, Areg and Levelt, Christiaan N. and Heimel, J. Alexander and Lorteije, Jeannette A. M. and {van der Togt}, Chris and Self, Matthew W. and Roelfsema, Pieter R.},
  year = {2021},
  month = jun,
  journal = {Science Advances},
  volume = {7},
  number = {27},
  pages = {eabe1833},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abe1833}
}

@misc{klindtNeuralSystem2018,
  title = {Neural System Identification for Large Populations Separating "What" and "Where"},
  author = {Klindt, David A. and Ecker, Alexander S. and Euler, Thomas and Bethge, Matthias},
  year = {2018},
  month = jan,
  number = {arXiv:1711.02653},
  eprint = {1711.02653},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.1711.02653},
  abstract = {Neuroscientists classify neurons into different types that perform similar computations at different locations in the visual field. Traditional methods for neural system identification do not capitalize on this separation of 'what' and 'where'. Learning deep convolutional feature spaces that are shared among many neurons provides an exciting path forward, but the architectural design needs to account for data limitations: While new experimental techniques enable recordings from thousands of neurons, experimental time is limited so that one can sample only a small fraction of each neuron's response space. Here, we show that a major bottleneck for fitting convolutional neural networks (CNNs) to neural data is the estimation of the individual receptive field locations, a problem that has been scratched only at the surface thus far. We propose a CNN architecture with a sparse readout layer factorizing the spatial (where) and feature (what) dimensions. Our network scales well to thousands of neurons and short recordings and can be trained end-to-end. We evaluate this architecture on ground-truth data to explore the challenges and limitations of CNN-based system identification. Moreover, we show that our network model outperforms current state-of-the art system identification models of mouse primary visual cortex.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Klindt et al_2018_Neural system identification for large populations separating what and where.pdf}
}

@misc{kornblithSimilarityNeural2019a,
  title = {Similarity of {{Neural Network Representations Revisited}}},
  author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  year = {2019},
  month = jul,
  number = {arXiv:1905.00414},
  eprint = {1905.00414},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.1905.00414},
  abstract = {Recent work has sought to understand the behavior of neural networks by comparing representations between layers and between different trained models. We examine methods for comparing neural network representations based on canonical correlation analysis (CCA). We show that CCA belongs to a family of statistics for measuring multivariate similarity, but that neither CCA nor any other statistic that is invariant to invertible linear transformation can measure meaningful similarities between representations of higher dimension than the number of data points. We introduce a similarity index that measures the relationship between representational similarity matrices and does not suffer from this limitation. This similarity index is equivalent to centered kernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA can reliably identify correspondences between representations in networks trained from different initializations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Kornblith et al_2019_Similarity of Neural Network Representations Revisited.pdf}
}

@misc{kubiliusBrainLikeObject2019,
  title = {Brain-{{Like Object Recognition}} with {{High-Performing Shallow Recurrent ANNs}}},
  author = {Kubilius, Jonas and Schrimpf, Martin and Kar, Kohitij and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Bashivan, Pouya and {Prescott-Roy}, Jonathan and Schmidt, Kailyn and Nayebi, Aran and Bear, Daniel and Yamins, Daniel L. K. and DiCarlo, James J.},
  year = {2019},
  month = oct,
  number = {arXiv:1909.06161},
  eprint = {1909.06161},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, q-bio},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.1909.06161},
  abstract = {Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain's anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S "IT" neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Electrical Engineering and Systems Science - Image and Video Processing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Kubilius et al_2019_Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs.pdf}
}

@article{kuninNeuralMechanics2021,
  title = {Neural {{Mechanics}}: {{Symmetry}} and {{Broken Conservation Laws}} in {{Deep Learning Dynamics}}},
  shorttitle = {Neural {{Mechanics}}},
  author = {Kunin, Daniel and {Sagastuy-Brena}, Javier and Ganguli, Surya and Yamins, Daniel L. K. and Tanaka, Hidenori},
  year = {2021},
  month = mar,
  journal = {arXiv:2012.04728 [cond-mat, q-bio, stat]},
  eprint = {2012.04728},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, q-bio, stat},
  abstract = {Understanding the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic expressions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Statistical Mechanics,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Kunin et al_2021_Neural Mechanics.pdf}
}

@article{leeNonlinearDimensionality2021,
  title = {Non-Linear Dimensionality Reduction on Extracellular Waveforms Reveals Cell Type Diversity in Premotor Cortex},
  author = {Lee, Eric Kenji and Balasubramanian, Hymavathy and Tsolias, Alexandra and Anakwe, Stephanie Udochukwu and Medalla, Maria and Shenoy, Krishna V and Chandrasekaran, Chandramouli},
  editor = {Salinas, Emilio and Frank, Michael J},
  year = {2021},
  month = aug,
  journal = {eLife},
  volume = {10},
  pages = {e67490},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.67490},
  abstract = {Cortical circuits are thought to contain a large number of cell types that coordinate to produce behavior. Current in vivo methods rely on clustering of specified features of extracellular waveforms to identify putative cell types, but these capture only a small amount of variation. Here, we develop a new method (WaveMAP) that combines non-linear dimensionality reduction with graph clustering to identify putative cell types. We apply WaveMAP to extracellular waveforms recorded from dorsal premotor cortex of macaque monkeys performing a decision-making task. Using WaveMAP, we robustly establish eight waveform clusters and show that these clusters recapitulate previously identified narrow- and broad-spiking types while revealing previously unknown diversity within these subtypes. The eight clusters exhibited distinct laminar distributions, characteristic firing rate patterns, and decision-related dynamics. Such insights were weaker when using feature-based approaches. WaveMAP therefore provides a more nuanced understanding of the dynamics of cell types in cortical circuits.},
  keywords = {cell types,circuits,layers,nonlinear dimensionality reduction,waveforms}
}

@article{lindsayTestingTools2022,
  title = {Testing the {{Tools}} of {{Systems Neuroscience}} on {{Artificial Neural Networks}}},
  author = {Lindsay, Grace W.},
  year = {2022},
  month = feb,
  journal = {arXiv:2202.07035 [cs, q-bio]},
  eprint = {2202.07035},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  abstract = {Neuroscientists apply a range of common analysis tools to recorded neural activity in order to glean insights into how neural circuits implement computations. Despite the fact that these tools shape the progress of the field as a whole, we have little empirical evidence that they are effective at quickly identifying the phenomena of interest. Here I argue that these tools should be explicitly tested and that artificial neural networks (ANNs) are an appropriate testing grounds for them. The recent resurgence of the use of ANNs as models of everything from perception to memory to motor control stems from a rough similarity between artificial and biological neural networks and the ability to train these networks to perform complex high-dimensional tasks. These properties, combined with the ability to perfectly observe and manipulate these systems, makes them well-suited for vetting the tools of systems and cognitive neuroscience. I provide here both a roadmap for performing this testing and a list of tools that are suitable to be tested on ANNs. Using ANNs to reflect on the extent to which these tools provide a productive understanding of neural systems -- and on exactly what understanding should mean here -- has the potential to expedite progress in the study of the brain.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition}
}

@misc{lindseyUnifiedTheory2019,
  title = {A {{Unified Theory Of Early Visual Representations From Retina To Cortex Through Anatomically Constrained Deep CNNs}}},
  author = {Lindsey, Jack and Ocko, Samuel A. and Ganguli, Surya and Deny, Stephane},
  year = {2019},
  month = jan,
  pages = {511535},
  institution = {{bioRxiv}},
  doi = {10.1101/511535},
  abstract = {The vertebrate visual system is hierarchically organized to process visual information in successive stages. Neural representations vary drastically across the first stages of visual processing: at the output of the retina, ganglion cell receptive fields (RFs) exhibit a clear antagonistic center-surround structure, whereas in the primary visual cortex (V1), typical RFs are sharply tuned to a precise orientation. There is currently no unified theory explaining these differences in representations across layers. Here, using a deep convolutional neural network trained on image recognition as a model of the visual system, we show that such differences in representation can emerge as a direct consequence of different neural resource constraints on the retinal and cortical networks, and for the first time we find a single model from which both geometries spontaneously emerge at the appropriate stages of visual processing. The key constraint is a reduced number of neurons at the retinal output, consistent with the anatomy of the optic nerve as a stringent bottleneck. Second, we find that, for simple downstream cortical networks, visual representations at the retinal output emerge as nonlinear and lossy feature detectors, whereas they emerge as linear and faithful encoders of the visual scene for more complex cortical networks. This result predicts that the retinas of small vertebrates (e.g. salamander, frog) should perform sophisticated nonlinear computations, extracting features directly relevant to behavior, whereas retinas of large animals such as primates should mostly encode the visual scene linearly and respond to a much broader range of stimuli. These predictions could reconcile the two seemingly incompatible views of the retina as either performing feature extraction or efficient coding of natural scenes, by suggesting that all vertebrates lie on a spectrum between these two objectives, depending on the degree of neural resources allocated to their visual system.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Lindsey et al_2019_A Unified Theory Of Early Visual Representations From Retina To Cortex Through.pdf}
}

@article{linImagingWholebrain2022,
  title = {Imaging Whole-Brain Activity to Understand Behaviour},
  author = {Lin, Albert and Witvliet, Daniel and {Hernandez-Nunez}, Luis and Linderman, Scott W. and Samuel, Aravinthan D. T. and Venkatachalam, Vivek},
  year = {2022},
  month = may,
  journal = {Nat Rev Phys},
  volume = {4},
  number = {5},
  pages = {292--305},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5820},
  doi = {10.1038/s42254-022-00430-w},
  abstract = {Until now, most brain studies have focused on small numbers of neurons that interact in limited circuits, allowing analysis of individual computations or steps of neural processing. During behaviour, however, brain activity must integrate multiple circuits in different brain regions. Whole-brain recording with cellular resolution provides a new opportunity to dissect the neural basis of behaviour, but whole-brain activity is mutually contingent on behaviour itself, especially for natural behaviours such as navigation, mating or hunting, which require dynamic interaction between the animal, its environment and other animals. Many of the signalling and feedback pathways that animals use to guide behaviour only occur in freely moving animals. Recent technological advances have enabled whole-brain recording in small behaving animals including the nematode Caenorhabditis elegans, the fruit fly Drosophila melanogaster and the larval zebrafish Danio rerio. These whole-brain experiments capture neural activity with cellular resolution spanning sensory, decision-making and motor circuits, and thereby demand new theoretical approaches that integrate brain dynamics with behavioural dynamics. We review the experimental and theoretical methods used to understand animal behaviour and whole-brain activity, and the opportunities for physics to contribute to this emerging field of systems neuroscience.},
  copyright = {2022 Springer Nature Limited},
  langid = {english},
  keywords = {Ca2+ imaging,Microscopy}
}

@inproceedings{linsleyStableExpressive2020,
  title = {Stable and Expressive Recurrent Vision Models},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Linsley, Drew and Karkada Ashok, Alekh and Govindarajan, Lakshmi Narasimhan and Liu, Rex and Serre, Thomas},
  year = {2020},
  volume = {33},
  pages = {10456--10467},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Primate vision depends on recurrent processing for reliable perception. A growing body of literature also suggests that recurrent connections improve the learning efficiency and generalization of vision models on classic computer vision challenges. Why then, are current large-scale challenges dominated by feedforward networks? We posit that the effectiveness of recurrent vision models is bottlenecked by the standard algorithm used for training them, "back-propagation through time" (BPTT), which has O(N) memory-complexity for training an N step model. Thus, recurrent vision model design is bounded by memory constraints, forcing a choice between rivaling the enormous capacity of leading feedforward models or trying to compensate for this deficit through granular and complex dynamics. Here, we develop a new learning algorithm, "contractor recurrent back-propagation" (C-RBP), which alleviates these issues by achieving constant O(1) memory-complexity with steps of recurrent processing. We demonstrate that recurrent vision models trained with C-RBP can detect long-range spatial dependencies in a synthetic contour tracing task that BPTT-trained models cannot. We further show that recurrent vision models trained with C-RBP to solve the large-scale Panoptic Segmentation MS-COCO challenge outperform the leading feedforward approach, with fewer free parameters. C-RBP is a general-purpose learning algorithm for any application that can benefit from expansive recurrent dynamics. Code and data are available at https://github.com/c-rbp.}
}

@article{lipovsekPatchseqPresent2021,
  title = {Patch-Seq: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {Patch-Seq},
  author = {Lipovsek, Marcela and Bardy, Cedric and Cadwell, Cathryn R. and Hadley, Kristen and Kobak, Dmitry and Tripathy, Shreejoy J.},
  year = {2021},
  month = feb,
  journal = {J. Neurosci.},
  volume = {41},
  number = {5},
  pages = {937--946},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1653-20.2020},
  abstract = {Single-cell transcriptomic approaches are revolutionizing neuroscience. Integrating this wealth of data with morphology and physiology, for the comprehensive study of neuronal biology, requires multiplexing gene expression data with complementary techniques. To meet this need, multiple groups in parallel have developed ``Patch-seq,'' a modification of whole-cell patch-clamp protocols that enables mRNA sequencing of cell contents after electrophysiological recordings from individual neurons and morphologic reconstruction of the same cells. In this review, we first outline the critical technical developments that enabled robust Patch-seq experimental efforts and analytical solutions to interpret the rich multimodal data generated. We then review recent applications of Patch-seq that address novel and long-standing questions in neuroscience. These include the following: (1) targeted study of specific neuronal populations based on their anatomic location, functional properties, lineage, or a combination of these factors; (2) the compilation and integration of multimodal cell type atlases; and (3) the investigation of the molecular basis of morphologic and functional diversity. Finally, we highlight potential opportunities for further technical development and lines of research that may benefit from implementing the Patch-seq technique. As a multimodal approach at the intersection of molecular neurobiology and physiology, Patch-seq is uniquely positioned to directly link gene expression to brain function.},
  chapter = {Symposium/Mini-Symposium},
  copyright = {Copyright \textcopyright{} 2021 the authors. SfN exclusive license.},
  langid = {english},
  pmid = {33431632},
  keywords = {electrophysiology,multi-modal,neuronal morphology,patch-clamp,single cell,transcriptomics},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Lipovsek et al_2021_Patch-seq.pdf}
}

@misc{luongoMicePrimates2021,
  title = {Mice and Primates Use Distinct Strategies for Visual Segmentation},
  author = {Luongo, Francisco J. and Liu, Lu and Ho, Chun Lum Andy and Hesse, Janis K. and Wekselblatt, Joseph B. and Lanfranchi, Francesco and Huber, Daniel and Tsao, Doris Y.},
  year = {2021},
  month = jul,
  pages = {2021.07.04.451059},
  institution = {{bioRxiv}},
  doi = {10.1101/2021.07.04.451059},
  abstract = {The rodent visual system has attracted great interest in recent years due to its experimental tractability, but the fundamental mechanisms used by the mouse to represent the visual world remain unclear. In the primate, researchers have argued from both behavioral and neural evidence that a key step in visual representation is ``figure-ground segmentation,'' the delineation of figures as distinct from backgrounds [1\textendash 4]. To determine if mice also show behavioral and neural signatures of figure-ground segmentation, we trained mice on a figure-ground segmentation task where figures were defined by gratings and naturalistic textures moving counterphase to the background. Unlike primates, mice were severely limited in their ability to segment figure from ground using the opponent motion cue, with segmentation behavior strongly dependent on the specific carrier pattern. Remarkably, when mice were forced to localize naturalistic patterns defined by opponent motion, they adopted a strategy of brute force memorization of texture patterns. In contrast, primates, including humans, macaques, and mouse lemurs, could readily segment figures independent of carrier pattern using the opponent motion cue. Consistent with mouse behavior, neural responses to the same stimuli recorded in mouse visual areas V1, RL, and LM also did not support texture-invariant segmentation of figures using opponent motion. Modeling revealed that the texture dependence of both the mouse's behavior and neural responses could be explained by a feedforward neural network lacking explicit segmentation capabilities. These findings reveal a fundamental limitation in the ability of mice to segment visual objects compared to primates.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Luongo et al_2021_Mice and primates use distinct strategies for visual segmentation.pdf}
}

@misc{luPretrainedTransformers2021,
  title = {Pretrained {{Transformers}} as {{Universal Computation Engines}}},
  author = {Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  year = {2021},
  month = jun,
  number = {arXiv:2103.05247},
  eprint = {2103.05247},
  eprinttype = {arxiv},
  primaryclass = {cs},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2103.05247},
  abstract = {We investigate the capability of a transformer pretrained on natural language to generalize to other modalities with minimal finetuning -- in particular, without finetuning of the self-attention and feedforward layers of the residual blocks. We consider such a model, which we call a Frozen Pretrained Transformer (FPT), and study finetuning it on a variety of sequence classification tasks spanning numerical computation, vision, and protein fold prediction. In contrast to prior works which investigate finetuning on the same modality as the pretraining dataset, we show that pretraining on natural language can improve performance and compute efficiency on non-language downstream tasks. Additionally, we perform an analysis of the architecture, comparing the performance of a random initialized transformer to a random LSTM. Combining the two insights, we find language-pretrained transformers can obtain strong performance on a variety of non-language tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Lu et al_2021_Pretrained Transformers as Universal Computation Engines.pdf}
}

@misc{lurzGeneralizationDatadriven2021,
  title = {Generalization in Data-Driven Models of Primary Visual Cortex},
  author = {Lurz, Konstantin-Klemens and Bashiri, Mohammad and Willeke, Konstantin and Jagadish, Akshay K. and Wang, Eric and Walker, Edgar Y. and Cadena, Santiago A. and Muhammad, Taliah and Cobos, Erick and Tolias, Andreas S. and Ecker, Alexander S. and Sinz, Fabian H.},
  year = {2021},
  month = apr,
  pages = {2020.10.05.326256},
  institution = {{bioRxiv}},
  doi = {10.1101/2020.10.05.326256},
  abstract = {Deep neural networks (DNN) have set new standards at predicting responses of neural populations to visual input. Most such DNNs consist of a convolutional network (core) shared across all neurons which learns a representation of neural computation in visual cortex and a neuron-specific readout that linearly combines the relevant features in this representation. The goal of this paper is to test whether such a representation is indeed generally characteristic for visual cortex, i.e. gener-alizes between animals of a species, and what factors contribute to obtaining such a generalizing core. To push all non-linear computations into the core where the generalizing cortical features should be learned, we devise a novel readout that reduces the number of parameters per neuron in the readout by up to two orders of magnitude compared to the previous state-of-the-art. It does so by taking advantage of retinotopy and learns a Gaussian distribution over the neuron's receptive field po-sition. With this new readout we train our network on neural responses from mouse primary visual cortex (V1) and obtain a gain in performance of 7\% compared to the previous state-of-the-art network. We then investigate whether the convolutional core indeed captures general cortical features by using the core in transfer learning to a different animal. When transferring a core trained on thousands of neurons from various animals and scans we exceed the performance of training directly on that animal by 12\%, and outperform a commonly used VGG16 core pre-trained on imagenet by 33\%. In addition, transfer learning with our data-driven core is more data-efficient than direct training, achieving the same performance with only 40\% of the data. Our model with its novel readout thus sets a new state-of-the-art for neural response prediction in mouse visual cortex from natural images, generalizes between animals, and captures better characteristic cortical features than current task-driven pre-training approaches such as VGG16.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english}
}

@misc{marshallFlexibleNeural2021,
  title = {Flexible Neural Control of Motor Units},
  author = {Marshall, Najja J. and Glaser, Joshua I. and Trautmann, Eric M. and Amematsro, Elom A. and Perkins, Sean M. and Shadlen, Michael N. and Abbott, L. F. and Cunningham, John P. and Churchland, Mark M.},
  year = {2021},
  month = may,
  pages = {2021.05.05.442653},
  institution = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2021.05.05.442653},
  abstract = {Voluntary movement requires communication from cortex to the spinal cord, where a dedicated pool of motor units (MUs) activates each muscle. The canonical description of MU function, established decades ago, rests upon two foundational tenets. First, cortex cannot control MUs independently1 but supplies each pool with a common drive that specifies force amplitude2,3. Second, as force rises, MUs are recruited in a consistent order4\textendash 13 typically described by Henneman's size principle14\textendash 19. While this paradigm has considerable empirical support, a direct test requires simultaneous observations of many MUs over a range of behaviors. We developed an isometric task that allowed stable MU recordings during rapidly changing force production. MU responses were surprisingly flexible and behavior-dependent. MU activity could not be accurately described as reflecting common drive, even when fit with highly expressive latent factor models. Neuropixels probe recordings revealed that, consistent with the requirements of fully flexible control, the cortical population response displays a surprisingly large number of degrees of freedom. Furthermore, MUs were differentially recruited by microstimulation at neighboring cortical sites. Thus, MU activities are flexibly controlled to meet task demands, and cortex has the capacity to contribute to that ability.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english}
}

@article{miconiSpontaneousEmergence2016,
  title = {Spontaneous Emergence of Fast Attractor Dynamics in a Model of Developing Primary Visual Cortex},
  author = {Miconi, Thomas and McKinstry, Jeffrey L. and Edelman, Gerald M.},
  year = {2016},
  month = oct,
  journal = {Nat Commun},
  volume = {7},
  number = {1},
  pages = {13208},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms13208},
  abstract = {Recent evidence suggests that neurons in primary sensory cortex arrange into competitive groups, representing stimuli by their joint activity rather than as independent feature analysers. A possible explanation for these results is that sensory cortex implements attractor dynamics, although this proposal remains controversial. Here we report that fast attractor dynamics emerge naturally in a computational model of a patch of primary visual cortex endowed with realistic plasticity (at both feedforward and lateral synapses) and mutual inhibition. When exposed to natural images (but not random pixels), the model spontaneously arranges into competitive groups of reciprocally connected, similarly tuned neurons, while developing realistic, orientation-selective receptive fields. Importantly, the same groups are observed in both stimulus-evoked and spontaneous (stimulus-absent) activity. The resulting network is inhibition-stabilized and exhibits fast, non-persistent attractor dynamics. Our results suggest that realistic plasticity, mutual inhibition and natural stimuli are jointly necessary and sufficient to generate attractor dynamics in primary sensory cortex.},
  copyright = {2016 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Network models;Neural circuits;Sensory processing;Synaptic development Subject\_term\_id: network-models;neural-circuit;sensory-processing;synaptic-development},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Miconi et al_2016_Spontaneous emergence of fast attractor dynamics in a model of developing.pdf}
}

@misc{milletRealisticModel2022,
  title = {Toward a Realistic Model of Speech Processing in the Brain with Self-Supervised Learning},
  author = {Millet, Juliette and Caucheteux, Charlotte and Orhan, Pierre and Boubenec, Yves and Gramfort, Alexandre and Dunbar, Ewan and Pallier, Christophe and King, Jean-Remi},
  year = {2022},
  month = jun,
  number = {arXiv:2206.01685},
  eprint = {2206.01685},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2206.01685},
  abstract = {Several deep neural networks have recently been shown to generate activations similar to those of the brain in response to the same input. These algorithms, however, remain largely implausible: they require (1) extraordinarily large amounts of data, (2) unobtainable supervised labels, (3) textual rather than raw sensory input, and / or (4) implausibly large memory (e.g. thousands of contextual words). These elements highlight the need to identify algorithms that, under these limitations, would suffice to account for both behavioral and brain responses. Focusing on the issue of speech processing, we here hypothesize that self-supervised algorithms trained on the raw waveform constitute a promising candidate. Specifically, we compare a recent self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412 English, French, and Mandarin individuals recorded with functional Magnetic Resonance Imaging (fMRI), while they listened to \textasciitilde 1h of audio books. Our results are four-fold. First, we show that this algorithm learns brain-like representations with as little as 600 hours of unlabelled speech -- a quantity comparable to what infants can be exposed to during language acquisition. Second, its functional hierarchy aligns with the cortical hierarchy of speech processing. Third, different training regimes reveal a functional specialization akin to the cortex: Wav2Vec 2.0 learns sound-generic, speech-specific and language-specific representations similar to those of the prefrontal and temporal cortices. Fourth, we confirm the similarity of this specialization with the behavior of 386 additional participants. These elements, resulting from the largest neuroimaging benchmark to date, show how self-supervised learning can account for a rich organization of speech processing in the brain, and thus delineate a path to identify the laws of language acquisition which shape the human brain.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Millet et al_2022_Toward a realistic model of speech processing in the brain with self-supervised.pdf}
}

@inproceedings{mineaultYourHead2021,
  title = {Your Head Is There to Move You around: {{Goal-driven}} Models of the Primate Dorsal Pathway},
  shorttitle = {Your Head Is There to Move You Around},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mineault, Patrick and Bakhtiari, Shahab and Richards, Blake and Pack, Christopher},
  year = {2021},
  volume = {34},
  pages = {28757--28771},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Neurons in the dorsal visual pathway of the mammalian brain are selective for motion stimuli, with the complexity of stimulus representations increasing along the hierarchy. This progression is similar to that of the ventral visual pathway, which is well characterized by artificial neural networks (ANNs) optimized for object recognition. In contrast, there are no image-computable models of the dorsal stream with comparable explanatory power. We hypothesized that the properties of dorsal stream neurons could be explained by a simple learning objective: the need for an organism to orient itself during self-motion. To test this hypothesis, we trained a 3D ResNet to predict an agent's self-motion parameters from visual stimuli in a simulated environment. We found that the responses in this network accounted well for the selectivity of neurons in a large database of single-neuron recordings from the dorsal visual stream of non-human primates. In contrast, ANNs trained on an action recognition dataset through supervised or self-supervised learning  could not explain responses in the dorsal stream, despite also being trained on naturalistic videos with moving objects. These results demonstrate that an ecologically relevant cost function can account for dorsal stream properties in the primate brain.}
}

@article{naikActiveMachine2016,
  title = {Active Machine Learning-Driven Experimentation to Determine Compound Effects on Protein Patterns},
  author = {Naik, Armaghan W and Kangas, Joshua D and Sullivan, Devin P and Murphy, Robert F},
  editor = {Ohler, Uwe},
  year = {2016},
  month = feb,
  journal = {eLife},
  volume = {5},
  pages = {e10047},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.10047},
  abstract = {High throughput screening determines the effects of many conditions on a given biological target. Currently, to estimate the effects of those conditions on other targets requires either strong modeling assumptions (e.g. similarities among targets) or separate screens. Ideally, data-driven experimentation could be used to learn accurate models for many conditions and targets without doing all possible experiments. We have previously described an active machine learning algorithm that can iteratively choose small sets of experiments to learn models of multiple effects. We now show that, with no prior knowledge and with liquid handling robotics and automated microscopy under its control, this learner accurately learned the effects of 48 chemical compounds on the subcellular localization of 48 proteins while performing only 29\% of all possible experiments. The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes is unknown in advance.},
  keywords = {active learning,automation of research,high content screening,laboratory automation,machine learning,protein subcellular location},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroProfiles/PhD/Data/storage/5L8INKE2/Naik et al_2016_Active machine learning-driven experimentation to determine compound effects on.pdf}
}

@misc{nayebiShallowUnsupervised2021,
  title = {Shallow {{Unsupervised Models Best Predict Neural Responses}} in {{Mouse Visual Cortex}}},
  author = {Nayebi, Aran and Kong, Nathan C. L. and Zhuang, Chengxu and Gardner, Justin L. and Norcia, Anthony M. and Yamins, Daniel L. K.},
  year = {2021},
  month = aug,
  pages = {2021.06.16.448730},
  institution = {{bioRxiv}},
  doi = {10.1101/2021.06.16.448730},
  abstract = {Task-optimized deep convolutional neural networks are the most quantitatively accurate models of the primate ventral visual stream. However, such networks are implausible as models of the mouse visual system because mouse visual cortex has both lower retinal resolution and a shallower hierarchy than the primate. Moreover, the category supervision deep networks typically receive is neither ethologically relevant to the mouse in semantic content, nor realistic in quantity. As a result, standard supervised deep neural networks have proven quantitatively ineffective at modeling mouse visual data. Here, we develop and evaluate models that remedy these structural and functional gaps. We first demonstrate that shallow hierarchical architectures applied to lower resolution images improve match to neural responses, both in electro-physiological and calcium imaging data. We then show that networks trained using contrastive embedding methods, a recent unsupervised learning objective that requires no semantic labeling, achieve neural prediction performance that substantially exceed that of the same architectures trained in a supervised manner, across a wide variety of architecture types. Combining these better structural and functional priors yields models that are the most quantitatively accurate match to mouse visual responses to natural scenes, significantly surpassing that of prior attempts using primate-specific models, and approaching the inter-animal consistency level of the data itself. We further find that these shallow unsupervised models transfer to a wide variety of non-categorical visual tasks better than categorization-trained models. Taken together, our results suggest that mouse visual cortex is a low-resolution, shallow network that makes best use of the mouse's limited resources to create a light-weight, general-purpose visual system \textendash{} in contrast to the deep, high-resolution, and more task-specific visual system of primates.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Nayebi et al_2021_Shallow Unsupervised Models Best Predict Neural Responses in Mouse Visual Cortex.pdf}
}

@inproceedings{nayebiTaskDrivenConvolutional2018,
  title = {Task-{{Driven Convolutional Recurrent Models}} of the {{Visual System}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Nayebi, Aran and Bear, Daniel and Kubilius, Jonas and Kar, Kohitij and Ganguli, Surya and Sussillo, David and DiCarlo, James J and Yamins, Daniel L},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Feed-forward convolutional neural networks (CNNs) are currently state-of-the-art for object classification tasks such as ImageNet. Further, they are quantitatively accurate models of temporally-averaged responses of neurons in the primate brain's visual system.  However, biological visual systems have two ubiquitous architectural features not shared with typical CNNs: local recurrence within cortical areas, and long-range feedback from downstream areas to upstream areas.  Here we explored the role of recurrence in improving classification performance. We found that standard forms of recurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the ImageNet task. In contrast, novel cells that incorporated two structural features, bypassing and gating, were able to boost task accuracy substantially. We extended these design principles in an automated search over thousands of model architectures, which identified novel local recurrent cells and long-range feedback connections useful for object recognition. Moreover, these task-optimized ConvRNNs matched the dynamics of neural activity in the primate visual system better than feedforward networks, suggesting a role for the brain's recurrent connections in performing difficult visual behaviors.}
}

@article{neftciReinforcementLearning2019,
  title = {Reinforcement Learning in Artificial and Biological Systems},
  author = {Neftci, Emre O. and Averbeck, Bruno B.},
  year = {2019},
  month = mar,
  journal = {Nat Mach Intell},
  volume = {1},
  number = {3},
  pages = {133--143},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0025-4},
  abstract = {There is and has been a fruitful flow of concepts and ideas between studies of learning in biological and artificial systems. Much early work that led to the development of reinforcement learning (RL) algorithms for artificial systems was inspired by learning rules first developed in biology by Bush and Mosteller, and Rescorla and Wagner. More recently, temporal-difference RL, developed for learning in artificial agents, has provided a foundational framework for interpreting the activity of dopamine neurons. In this Review, we describe state-of-the-art work on RL in biological and artificial agents. We focus on points of contact between these disciplines and identify areas where future research can benefit from information flow between these fields. Most work in biological systems has focused on simple learning problems, often embedded in dynamic environments where flexibility and ongoing learning are important, similar to real-world learning problems faced by biological systems. In contrast, most work in artificial agents has focused on learning a single complex problem in a static environment. Moving forward, work in each field will benefit from a flow of ideas that represent the strengths within each discipline.},
  copyright = {2019 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  langid = {english}
}

@article{neftciSurrogateGradient2019,
  title = {Surrogate {{Gradient Learning}} in {{Spiking Neural Networks}}: {{Bringing}} the {{Power}} of {{Gradient-Based Optimization}} to {{Spiking Neural Networks}}},
  shorttitle = {Surrogate {{Gradient Learning}} in {{Spiking Neural Networks}}},
  author = {Neftci, Emre O. and Mostafa, Hesham and Zenke, Friedemann},
  year = {2019},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {36},
  number = {6},
  pages = {51--63},
  issn = {1558-0792},
  doi = {10.1109/MSP.2019.2931595},
  abstract = {Spiking neural networks (SNNs) are nature's versatile solution to fault-tolerant, energy-efficient signal processing. To translate these benefits into hardware, a growing number of neuromorphic spiking NN processors have attempted to emulate biological NNs. These developments have created an imminent need for methods and tools that enable such systems to solve real-world signal processing problems. Like conventional NNs, SNNs can be trained on real, domain-specific data; however, their training requires the overcoming of a number of challenges linked to their binary and dynamical nature. This article elucidates step-by-step the problems typically encountered when training SNNs and guides the reader through the key concepts of synaptic plasticity and data-driven learning in the spiking setting. Accordingly, it gives an overview of existing approaches and provides an introduction to surrogate gradient (SG) methods, specifically, as a particularly flexible and efficient method to overcome the aforementioned challenges.},
  keywords = {Biological system modeling,Energy efficiency,Fault tolerance,Neural networks}
}

@misc{NewEra2021,
  title = {A {{New Era}} in {{Neural Recording Part}} 2: {{A Flexible Solution}}},
  shorttitle = {A {{New Era}} in {{Neural Recording Part}} 2},
  year = {2021},
  month = jul,
  journal = {Simons Foundation},
  abstract = {A New Era in Neural Recording Part 2: A Flexible Solution on Simons Foundation},
  howpublished = {https://www.simonsfoundation.org/2021/07/19/a-new-era-in-neural-recording-part-2-a-flexible-solution/},
  langid = {american}
}

@article{nobleTheoryBiological2012,
  title = {A Theory of Biological Relativity: No Privileged Level of Causation},
  shorttitle = {A Theory of Biological Relativity},
  author = {Noble, Denis},
  year = {2012},
  month = feb,
  journal = {Interface Focus},
  volume = {2},
  number = {1},
  pages = {55--64},
  publisher = {{Royal Society}},
  doi = {10.1098/rsfs.2011.0067},
  abstract = {Must higher level biological processes always be derivable from lower level data and mechanisms, as assumed by the idea that an organism is completely defined by its genome? Or are higher level properties necessarily also causes of lower level behaviour, involving actions and interactions both ways? This article uses modelling of the heart, and its experimental basis, to show that downward causation is necessary and that this form of causation can be represented as the influences of initial and boundary conditions on the solutions of the differential equations used to represent the lower level processes. These insights are then generalized. A priori, there is no privileged level of causation. The relations between this form of `biological relativity' and forms of relativity in physics are discussed. Biological relativity can be seen as an extension of the relativity principle by avoiding the assumption that there is a privileged scale at which biological functions are determined.},
  keywords = {biological relativity,cardiac cell model,downward causation,scale relativity},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Noble_2012_A theory of biological relativity.pdf}
}

@article{parkerKuhnianRevolutions2018,
  title = {Kuhnian Revolutions in Neuroscience: The Role of Tool Development},
  shorttitle = {Kuhnian Revolutions in Neuroscience},
  author = {Parker, David},
  year = {2018},
  month = may,
  journal = {Biol Philos},
  volume = {33},
  number = {3},
  pages = {17},
  issn = {1572-8404},
  doi = {10.1007/s10539-018-9628-0},
  abstract = {The terms ``paradigm'' and ``paradigm shift'' originated in ``The Structure of Scientific Revolutions'' by Thomas Kuhn. A paradigm can be defined as the generally accepted concepts and practices of a field, and a paradigm shift its replacement in a scientific revolution. A paradigm shift results from a crisis caused by anomalies in a paradigm that reduce its usefulness to a field. Claims of paradigm shifts and revolutions are made frequently in the neurosciences. In this article I will consider neuroscience paradigms, and the claim that new tools and techniques rather than crises have driven paradigm shifts. I will argue that tool development has played a minor role in neuroscience revolutions.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Parker_2018_Kuhnian revolutions in neuroscience.pdf}
}

@misc{pasadLayerwiseAnalysis2021,
  title = {Layer-Wise {{Analysis}} of a {{Self-supervised Speech Representation Model}}},
  author = {Pasad, Ankita and Chou, Ju-Chieh and Livescu, Karen},
  year = {2021},
  month = oct,
  number = {arXiv:2107.04734},
  eprint = {2107.04734},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2107.04734},
  abstract = {Recently proposed self-supervised learning approaches have been successful for pre-training speech representation models. The utility of these learned representations has been observed empirically, but not much has been studied about the type or extent of information encoded in the pre-trained representations themselves. Developing such insights can help understand the capabilities and limits of these models and enable the research community to more efficiently develop their usage for downstream applications. In this work, we begin to fill this gap by examining one recent and successful pre-trained model (wav2vec 2.0), via its intermediate representation vectors, using a suite of analysis tools. We use the metrics of canonical correlation, mutual information, and performance on simple downstream tasks with non-parametric probes, in order to (i) query for acoustic and linguistic information content, (ii) characterize the evolution of information across model layers, and (iii) understand how fine-tuning the model for automatic speech recognition (ASR) affects these observations. Our findings motivate modifying the fine-tuning protocol for ASR, which produces improved word error rates in a low-resource setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Pasad et al_2021_Layer-wise Analysis of a Self-supervised Speech Representation Model.pdf}
}

@article{payeurBurstdependentSynaptic2021,
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  year = {2021},
  month = jul,
  journal = {Nat Neurosci},
  volume = {24},
  number = {7},
  pages = {1010--1019},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00857-x},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well established that it depends on pre- and postsynaptic activity. However, models that rely solely on pre- and postsynaptic activity for synaptic changes have, so far, not been able to account for learning complex tasks that demand credit assignment in hierarchical networks. Here we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then pyramidal neurons higher in a hierarchical circuit can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Learning algorithms;Sensory processing;Spike-timing-dependent plasticity Subject\_term\_id: learning-algorithms;sensory-processing;spike-timing-dependent-plasticity},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Payeur et al_2021_Burst-dependent synaptic plasticity can coordinate learning in hierarchical.pdf}
}

@article{pospisilUnbiasedEstimation2021,
  title = {The Unbiased Estimation of the Fraction of Variance Explained by a Model},
  author = {Pospisil, Dean A. and Bair, Wyeth},
  year = {2021},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {8},
  pages = {e1009212},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009212},
  abstract = {The correlation coefficient squared, r2, is commonly used to validate quantitative models on neural data, yet it is biased by trial-to-trial variability: as trial-to-trial variability increases, measured correlation to a model's predictions decreases. As a result, models that perfectly explain neural tuning can appear to perform poorly. Many solutions to this problem have been proposed, but no consensus has been reached on which is the least biased estimator. Some currently used methods substantially overestimate model fit, and the utility of even the best performing methods is limited by the lack of confidence intervals and asymptotic analysis. We provide a new estimator, r \^ ER 2, that outperforms all prior estimators in our testing, and we provide confidence intervals and asymptotic guarantees. We apply our estimator to a variety of neural data to validate its utility. We find that neural noise is often so great that confidence intervals of the estimator cover the entire possible range of values ([0, 1]), preventing meaningful evaluation of the quality of a model's predictions. This leads us to propose the use of the signal-to-noise ratio (SNR) as a quality metric for making quantitative comparisons across neural recordings. Analyzing a variety of neural data sets, we find that up to {$\sim$} 40\% of some state-of-the-art neural recordings do not pass even a liberal SNR criterion. Moving toward more reliable estimates of correlation, and quantitatively comparing quality across recording modalities and data sets, will be critical to accelerating progress in modeling biological phenomena.},
  langid = {english},
  keywords = {Action potentials,Electrophysiology,Neuronal tuning,Neurons,Sensory perception,Signal to noise ratio,Simulation and modeling,Vision}
}

@inproceedings{raghuVisionTransformers2021,
  title = {Do {{Vision Transformers See Like Convolutional Neural Networks}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  year = {2021},
  month = may,
  abstract = {We use representation analysis methods to study Vision Transformers and understand differences between them and CNNs.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Raghu et al_2021_Do Vision Transformers See Like Convolutional Neural Networks.pdf}
}

@article{rajalinghamLargeScaleHighResolution2018,
  title = {Large-{{Scale}}, {{High-Resolution Comparison}} of the {{Core Visual Object Recognition Behavior}} of {{Humans}}, {{Monkeys}}, and {{State-of-the-Art Deep Artificial Neural Networks}}},
  author = {Rajalingham, Rishi and Issa, Elias B. and Bashivan, Pouya and Kar, Kohitij and Schmidt, Kailyn and DiCarlo, James J.},
  year = {2018},
  month = aug,
  journal = {J. Neurosci.},
  volume = {38},
  number = {33},
  pages = {7255--7269},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0388-18.2018},
  abstract = {Primates, including humans, can typically recognize objects in visual images at a glance despite naturally occurring identity-preserving image transformations (e.g., changes in viewpoint). A primary neuroscience goal is to uncover neuron-level mechanistic models that quantitatively explain this behavior by predicting primate performance for each and every image. Here, we applied this stringent behavioral prediction test to the leading mechanistic models of primate vision (specifically, deep, convolutional, artificial neural networks; ANNs) by directly comparing their behavioral signatures against those of humans and rhesus macaque monkeys. Using high-throughput data collection systems for human and monkey psychophysics, we collected more than one million behavioral trials from 1472 anonymous humans and five male macaque monkeys for 2400 images over 276 binary object discrimination tasks. Consistent with previous work, we observed that state-of-the-art deep, feedforward convolutional ANNs trained for visual categorization (termed DCNNIC models) accurately predicted primate patterns of object-level confusion. However, when we examined behavioral performance for individual images within each object discrimination task, we found that all tested DCNNIC models were significantly nonpredictive of primate performance and that this prediction failure was not accounted for by simple image attributes nor rescued by simple model modifications. These results show that current DCNNIC models cannot account for the image-level behavioral patterns of primates and that new ANN models are needed to more precisely capture the neural mechanisms underlying primate object vision. To this end, large-scale, high-resolution primate behavioral benchmarks such as those obtained here could serve as direct guides for discovering such models. SIGNIFICANCE STATEMENT Recently, specific feedforward deep convolutional artificial neural networks (ANNs) models have dramatically advanced our quantitative understanding of the neural mechanisms underlying primate core object recognition. In this work, we tested the limits of those ANNs by systematically comparing the behavioral responses of these models with the behavioral responses of humans and monkeys at the resolution of individual images. Using these high-resolution metrics, we found that all tested ANN models significantly diverged from primate behavior. Going forward, these high-resolution, large-scale primate behavioral benchmarks could serve as direct guides for discovering better ANN models of the primate visual system.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2018 the authors 0270-6474/18/387255-15\$15.00/0},
  langid = {english},
  pmid = {30006365},
  keywords = {deep neural network,human,monkey,object recognition,vision},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Rajalingham et al_2018_Large-Scale, High-Resolution Comparison of the Core Visual Object Recognition.pdf}
}

@article{rajanRecurrentNetwork2016,
  title = {Recurrent {{Network Models}} of {{Sequence Generation}} and {{Memory}}},
  author = {Rajan, Kanaka and Harvey, Christopher D. and Tank, David W.},
  year = {2016},
  month = apr,
  journal = {Neuron},
  volume = {90},
  number = {1},
  pages = {128--142},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.02.009},
  abstract = {Sequential activation of neurons is a common feature of network activity during a variety of behaviors, including working memory and decision making. Previous network models for sequences and memory emphasized specialized architectures in which a principled mechanism is pre-wired into their connectivity. Here we demonstrate that, starting from random connectivity and modifying a small fraction of connections, a largely disordered recurrent network can produce sequences and implement working memory efficiently. We use this process, called Partial In-Network Training (PINning), to model and match cellular resolution imaging data from the posterior parietal cortex during a virtual memory-guided two-alternative forced-choice task. Analysis of the connectivity reveals that sequences propagate by the cooperation between recurrent synaptic interactions and external inputs, rather than through feedforward or asymmetric connections. Together our results suggest that neural sequences may emerge through learning from largely unstructured network architectures.},
  langid = {english}
}

@inproceedings{riedelBagTricks2022,
  title = {Bag of {{Tricks}} for {{Training Brain-Like Deep Neural Networks}}},
  booktitle = {Brain-{{Score Workshop}}},
  author = {Riedel, Alexander},
  year = {2022},
  month = mar,
  abstract = {The human-level performance of artificial neural networks (ANNs) in visual processing has made them a much-used research subject for understanding how the visual cortex really works. To assess how...},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Riedel_2022_Bag of Tricks for Training Brain-Like Deep Neural Networks.pdf}
}

@article{roySpikebasedMachine2019,
  title = {Towards Spike-Based Machine Intelligence with Neuromorphic Computing},
  author = {Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
  year = {2019},
  month = nov,
  journal = {Nature},
  volume = {575},
  number = {7784},
  pages = {607--617},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1677-2},
  abstract = {Guided by brain-like `spiking' computational frameworks, neuromorphic computing\textemdash brain-inspired computing for machine intelligence\textemdash promises to realize artificial intelligence while reducing the energy requirements of computing platforms. This interdisciplinary field began with the implementation of silicon circuits for biological neural routines, but has evolved to encompass the hardware implementation of algorithms with spike-based encoding and event-driven representations. Here we provide an overview of the developments in neuromorphic computing for both algorithms and hardware and highlight the fundamentals of learning and hardware frameworks. We discuss the main challenges and the future prospects of neuromorphic computing, with emphasis on~algorithm\textendash hardware codesign.},
  copyright = {2019 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Electrical and electronic engineering;Nanoscience and technology Subject\_term\_id: electrical-and-electronic-engineering;nanoscience-and-technology}
}

@article{rustPriorityCoding2022,
  title = {Priority Coding in the Visual System},
  author = {Rust, Nicole C. and Cohen, Marlene R.},
  year = {2022},
  month = jun,
  journal = {Nat Rev Neurosci},
  volume = {23},
  number = {6},
  pages = {376--388},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00582-9},
  abstract = {Although we are continuously bombarded with visual input, only a fraction of incoming visual events is perceived, remembered or acted on. The neural underpinnings of various forms of visual priority coding, including perceptual expertise, goal-directed attention, visual salience, image memorability and preferential looking, have been studied. Here, we synthesize information from these different examples to review recent developments in our understanding of visual priority coding and its neural correlates, with a focus on the role of behaviour to evaluate candidate correlates. We propose that the brain combines different types of priority into a unified priority signal while also retaining the ability to differentiate between them, and that this happens by leveraging partially overlapping low-dimensional neural subspaces for each type of priority that are shared with the downstream neural populations involved in decision-making. Finally, we describe the gulfs in understanding that have resulted from different research approaches, and we point towards future directions that will lead to fundamental insights about neural coding and how prioritization influences visually guided behaviours.},
  copyright = {2022 Springer Nature Limited},
  langid = {english},
  keywords = {Extrastriate cortex,Neural encoding},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Rust_Cohen_2022_Priority coding in the visual system.pdf}
}

@article{sadehInhibitoryStabilization2021,
  title = {Inhibitory Stabilization and Cortical Computation},
  author = {Sadeh, Sadra and Clopath, Claudia},
  year = {2021},
  month = jan,
  journal = {Nat Rev Neurosci},
  volume = {22},
  number = {1},
  pages = {21--37},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-00390-z},
  abstract = {Neuronal networks with strong recurrent connectivity provide the brain with a powerful means to perform complex computational tasks. However, high-gain excitatory networks are susceptible to instability, which can lead to runaway activity, as manifested in pathological regimes such as epilepsy. Inhibitory stabilization offers a dynamic, fast and flexible compensatory mechanism to balance otherwise unstable networks, thus enabling the brain to operate in its most efficient regimes. Here we review recent experimental evidence for the presence of such inhibition-stabilized dynamics in the brain and discuss their consequences for cortical computation. We show how the study of inhibition-stabilized networks in the brain has been facilitated by recent advances in the technological toolbox and perturbative techniques, as well as a concomitant development of biologically realistic computational models. By outlining future avenues, we suggest that inhibitory stabilization can offer an exemplary case of how experimental neuroscience can progress in tandem with technology and theory to advance our understanding of the brain.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Dynamical systems;Network models;Neural circuits;Sensorimotor processing Subject\_term\_id: dynamical-systems;network-models;neural-circuit;sensorimotor-processing}
}

@inproceedings{safaraniRobustVision2021,
  title = {Towards Robust Vision by Multi-Task Learning on Monkey Visual Cortex},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Safarani, Shahd and Nix, Arne and Willeke, Konstantin Friedrich and Cadena, Santiago A. and Restivo, Kelli and Denfield, George and Tolias, Andreas S. and Sinz, Fabian H.},
  year = {2021},
  month = may,
  abstract = {This work is about improving the robustness of artificial neural networks for object recognition by co-training with neural data.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Safarani et al_2021_Towards robust vision by multi-task learning on monkey visual cortex.pdf}
}

@article{saxeIfDeep2021,
  title = {If Deep Learning Is the Answer, What Is the Question?},
  author = {Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher},
  year = {2021},
  month = jan,
  journal = {Nat Rev Neurosci},
  volume = {22},
  number = {1},
  pages = {55--67},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-00395-8},
  abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Learning algorithms;Network models Subject\_term\_id: learning-algorithms;network-models},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Saxe et al_2021_If deep learning is the answer, what is the question.pdf}
}

@article{saxenaNeuralPopulation2019,
  title = {Towards the Neural Population Doctrine},
  author = {Saxena, Shreya and Cunningham, John P},
  year = {2019},
  month = apr,
  journal = {Current Opinion in Neurobiology},
  series = {Machine {{Learning}}, {{Big Data}}, and {{Neuroscience}}},
  volume = {55},
  pages = {103--111},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.02.002},
  abstract = {Across neuroscience, large-scale data recording and population-level analysis methods have experienced explosive growth. While the underlying hardware and computational techniques have been well reviewed, we focus here on the novel science that these technologies have enabled. We detail four areas of the field where the joint analysis of neural populations has significantly furthered our understanding of computation in the brain: correlated variability, decoding, neural dynamics, and artificial neural networks. Together, these findings suggest an exciting trend towards a new era where neural populations are understood to be the essential unit of computation in many brain regions, a classic idea that has been given new life.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Saxena_Cunningham_2019_Towards the neural population doctrine.pdf}
}

@article{scalaPhenotypicVariation2020,
  title = {Phenotypic Variation of Transcriptomic Cell Types in Mouse Motor Cortex},
  author = {Scala, Federico and Kobak, Dmitry and Bernabucci, Matteo and Bernaerts, Yves and Cadwell, Cathryn Ren{\'e} and Castro, Jesus Ramon and Hartmanis, Leonard and Jiang, Xiaolong and Laturnus, Sophie and Miranda, Elanine and Mulherkar, Shalaka and Tan, Zheng Huan and Yao, Zizhen and Zeng, Hongkui and Sandberg, Rickard and Berens, Philipp and Tolias, Andreas S.},
  year = {2020},
  month = nov,
  journal = {Nature},
  pages = {1--7},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2907-3},
  abstract = {Cortical neurons exhibit extreme diversity in gene expression as well as in morphological and electrophysiological properties1,2. Most existing neural taxonomies are based on either transcriptomic3,4 or morpho-electric5,6 criteria, as it has been technically challenging to study both aspects of neuronal diversity in the same set of cells7. Here we used Patch-seq8 to combine patch-clamp recording, biocytin staining, and single-cell RNA sequencing of more than 1,300 neurons in adult mouse primary motor cortex, providing a morpho-electric annotation of almost all transcriptomically defined neural cell types. We found that, although broad families of transcriptomic types (those expressing Vip, Pvalb, Sst and so on) had distinct and essentially non-overlapping morpho-electric phenotypes, individual transcriptomic types within the same family were not well separated in the morpho-electric space. Instead, there was a continuum of variability in morphology and electrophysiology, with neighbouring transcriptomic cell types showing similar morpho-electric features, often without clear boundaries between them. Our results suggest that neuronal types in the neocortex do not always form discrete entities. Instead, neurons form a hierarchy that consists of distinct non-overlapping branches at the level of families, but can form continuous and correlated transcriptomic and morpho-electrical landscapes within families.},
  copyright = {2020 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Cellular neuroscience;Genetics of the nervous system Subject\_term\_id: cellular-neuroscience;genetics-of-the-nervous-system},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Scala et al_2020_Phenotypic variation of transcriptomic cell types in mouse motor cortex.pdf}
}

@article{schneiderRethinkingDrug2020,
  title = {Rethinking Drug Design in the Artificial Intelligence Era},
  author = {Schneider, Petra and Walters, W. Patrick and Plowright, Alleyn T. and Sieroka, Norman and Listgarten, Jennifer and Goodnow, Robert A. and Fisher, Jasmin and Jansen, Johanna M. and Duca, Jos{\'e} S. and Rush, Thomas S. and Zentgraf, Matthias and Hill, John Edward and Krutoholow, Elizabeth and Kohler, Matthias and Blaney, Jeff and Funatsu, Kimito and Luebkemann, Chris and Schneider, Gisbert},
  year = {2020},
  month = may,
  journal = {Nat Rev Drug Discov},
  volume = {19},
  number = {5},
  pages = {353--364},
  publisher = {{Nature Publishing Group}},
  issn = {1474-1784},
  doi = {10.1038/s41573-019-0050-3},
  abstract = {Artificial intelligence (AI) tools are increasingly being applied in drug discovery. While some protagonists point to vast opportunities potentially offered by such tools, others remain sceptical, waiting for a clear impact to be shown in drug discovery projects. The reality is probably somewhere in-between these extremes, yet it is clear that AI is providing new challenges not only for the scientists involved but also for the biopharma industry and its established processes for discovering and developing new medicines. This article presents the views of a diverse group of international experts on the `grand challenges' in small-molecule drug discovery with AI and the approaches to address them.},
  copyright = {2019 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Computational chemistry;Drug development;Drug screening;Drug therapy;Small molecules Subject\_term\_id: computational-chemistry;drug-development;drug-screening;drug-therapy;small-molecules}
}

@inproceedings{sinzStimulusDomain2018,
  title = {Stimulus Domain Transfer in Recurrent Models for Large Scale Cortical Population Prediction on Video},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sinz, Fabian and Ecker, Alexander S and Fahey, Paul and Walker, Edgar and Cobos, Erick and Froudarakis, Emmanouil and Yatsenko, Dimitri and Pitkow, Zachary and Reimer, Jacob and Tolias, Andreas},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  abstract = {To better understand the representations in visual cortex, we need to generate better predictions of neural activity in awake animals presented with their ecological input: natural video. Despite recent advances in models for static images, models for predicting responses to natural video are scarce and standard linear-nonlinear models perform poorly. We developed a new deep recurrent network architecture that predicts inferred spiking activity of thousands of mouse V1 neurons simultaneously recorded with two-photon microscopy, while accounting for confounding factors such as the animal's gaze position and brain state changes related to running state and pupil dilation. Powerful system identification models provide an opportunity to gain insight into cortical functions through in silico experiments that can subsequently be tested in the brain. However, in many cases this approach requires that the model is able to generalize to stimulus statistics that it was not trained on, such as band-limited noise and other parameterized stimuli. We investigated these domain transfer properties in our model and find that our model trained on natural images is able to correctly predict the orientation tuning of neurons in responses to artificial noise stimuli. Finally, we show that we can fully generalize from movies to noise and maintain high predictive performance on both stimulus domains by fine-tuning only the final layer's weights on a network otherwise trained on natural movies. The converse, however, is not true.}
}

@article{st-yvesFeatureweightedReceptive2018,
  title = {The Feature-Weighted Receptive Field: An Interpretable Encoding Model for Complex Feature Spaces},
  shorttitle = {The Feature-Weighted Receptive Field},
  author = {{St-Yves}, Ghislain and Naselaris, Thomas},
  year = {2018},
  month = oct,
  journal = {NeuroImage},
  series = {New Advances in Encoding and Decoding of Brain Signals},
  volume = {180},
  pages = {188--202},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2017.06.035},
  abstract = {We introduce the feature-weighted receptive field (fwRF), an encoding model designed to balance expressiveness, interpretability and scalability. The fwRF is organized around the notion of a feature map\textemdash a transformation of visual stimuli into visual features that preserves the topology of visual space (but not necessarily the native resolution of the stimulus). The key assumption of the fwRF~model is that activity in each voxel encodes variation in a spatially localized region across multiple feature maps. This region is fixed for all feature maps; however, the contribution of each feature map to voxel activity is weighted. Thus, the model has two separable sets of parameters: ``where'' parameters that characterize the location and extent of pooling over visual features, and ``what'' parameters that characterize tuning to visual features. The ``where'' parameters are analogous to classical receptive fields, while ``what'' parameters are analogous to classical tuning functions. By treating these as separable parameters, the fwRF~model complexity is independent of the resolution of the underlying feature maps. This makes it possible to estimate models with thousands of high-resolution feature maps from relatively small amounts of data. Once a fwRF~model has been estimated from data, spatial pooling and feature tuning can be read-off directly with no (or very little) additional post-processing or in-silico experimentation. We describe an optimization algorithm for estimating fwRF~models from data acquired during standard visual neuroimaging experiments. We then demonstrate the model's application to two distinct sets of features: Gabor wavelets and features supplied by a deep convolutional neural network. We show that when Gabor feature maps are used, the fwRF~model recovers receptive fields and spatial frequency tuning functions consistent with known organizational principles of the visual cortex. We also show that a fwRF~model can be used to regress entire deep convolutional networks against brain activity. The ability to use whole networks in a single encoding model yields state-of-the-art prediction accuracy. Our results suggest a wide variety of uses for the feature-weighted receptive field model, from retinotopic mapping with natural scenes, to regressing the activities of whole deep neural networks onto measured brain activity.},
  langid = {english},
  keywords = {Deep neural network,Feature-weighted receptive field,FMRI,Visual cortex,Voxel-wise encoding model}
}

@article{stanleyContinuousDiscrete2020,
  title = {Continuous and {{Discrete Neuron Types}} of the {{Adult Murine Striatum}}},
  author = {Stanley, Geoffrey and Gokce, Ozgun and Malenka, Robert C. and S{\"u}dhof, Thomas C. and Quake, Stephen R.},
  year = {2020},
  month = feb,
  journal = {Neuron},
  volume = {105},
  number = {4},
  pages = {688-699.e8},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.11.004},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}The mammalian striatum is involved in many complex behaviors and yet is composed largely of a single neuron class: the spiny projection neuron (SPN). It is unclear to what extent the functional specialization of the striatum is due to the molecular specialization of SPN subtypes. We sought to define the molecular and anatomical diversity of adult SPNs using single-cell RNA sequencing (scRNA-seq) and quantitative RNA \emph{in situ} hybridization (ISH). We computationally distinguished discrete versus continuous heterogeneity in scRNA-seq data and found that SPNs in the striatum can be classified into four major discrete types with no implied spatial relationship between them. Within these discrete types, we find continuous heterogeneity encoding spatial gradients of gene expression and defining anatomical location in a combinatorial mechanism. Our results suggest that neuronal circuitry has a substructure at far higher resolution than is typically interrogated, which is defined by the precise identity and location of a neuron.{$<$}/p{$>$}},
  langid = {english},
  pmid = {31813651},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Stanley et al_2020_Continuous and Discrete Neuron Types of the Adult Murine Striatum.pdf}
}

@article{steinmetzAberrantCortical2017,
  title = {Aberrant {{Cortical Activity}} in {{Multiple GCaMP6-Expressing Transgenic Mouse Lines}}},
  author = {Steinmetz, Nicholas A. and Buetfering, Christina and Lecoq, Jerome and Lee, Christian R. and Peters, Andrew J. and Jacobs, Elina A. K. and Coen, Philip and Ollerenshaw, Douglas R. and Valley, Matthew T. and de Vries, Saskia E. J. and Garrett, Marina and Zhuang, Jun and Groblewski, Peter A. and Manavi, Sahar and Miles, Jesse and White, Casey and Lee, Eric and Griffin, Fiona and Larkin, Joshua D. and Roll, Kate and Cross, Sissy and Nguyen, Thuyanh V. and Larsen, Rachael and Pendergraft, Julie and Daigle, Tanya and Tasic, Bosiljka and Thompson, Carol L. and Waters, Jack and Olsen, Shawn and Margolis, David J. and Zeng, Hongkui and Hausser, Michael and Carandini, Matteo and Harris, Kenneth D.},
  year = {2017},
  month = sep,
  journal = {eNeuro},
  volume = {4},
  number = {5},
  publisher = {{Society for Neuroscience}},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0207-17.2017},
  abstract = {Transgenic mouse lines are invaluable tools for neuroscience but, as with any technique, care must be taken to ensure that the tool itself does not unduly affect the system under study. Here we report aberrant electrical activity, similar to interictal spikes, and accompanying fluorescence events in some genotypes of transgenic mice expressing GCaMP6 genetically encoded calcium sensors. These epileptiform events have been observed particularly, but not exclusively, in mice with Emx1-Cre and Ai93 transgenes, of either sex, across multiple laboratories. The events occur at {$>$}0.1 Hz, are very large in amplitude ({$>$}1.0 mV local field potentials, {$>$}10\% df/f widefield imaging signals), and typically cover large regions of cortex. Many properties of neuronal responses and behavior seem normal despite these events, although rare subjects exhibit overt generalized seizures. The underlying mechanisms of this phenomenon remain unclear, but we speculate about possible causes on the basis of diverse observations. We encourage researchers to be aware of these activity patterns while interpreting neuronal recordings from affected mouse lines and when considering which lines to study.},
  chapter = {Methods/New Tools},
  copyright = {Copyright \textcopyright{} 2017 Steinmetz et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
  langid = {english},
  pmid = {28932809},
  keywords = {Cortex,epilepsy,GCaMP,transgenic},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Steinmetz et al_2017_Aberrant Cortical Activity in Multiple GCaMP6-Expressing Transgenic Mouse Lines.pdf}
}

@article{steinmetzDistributedCoding2019,
  title = {Distributed Coding of Choice, Action and Engagement across the Mouse Brain},
  author = {Steinmetz, Nicholas A. and {Zatka-Haas}, Peter and Carandini, Matteo and Harris, Kenneth D.},
  year = {2019},
  month = dec,
  journal = {Nature},
  volume = {576},
  number = {7786},
  pages = {266--273},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1787-x},
  abstract = {Vision, choice, action and behavioural engagement arise from neuronal activity that may be distributed across brain regions. Here we delineate the spatial distribution of neurons underlying these processes. We used Neuropixels probes1,2 to record from approximately 30,000 neurons in 42 brain regions of mice performing a visual discrimination task3. Neurons in nearly all regions responded non-specifically when the mouse initiated an action. By contrast, neurons encoding visual stimuli and upcoming choices occupied restricted regions in the~neocortex, basal ganglia and midbrain. Choice signals were rare and emerged with indistinguishable timing across regions. Midbrain neurons were activated before contralateral choices and were suppressed before ipsilateral choices, whereas forebrain neurons could prefer either side. Brain-wide pre-stimulus activity predicted engagement in individual trials and in the overall task, with enhanced subcortical but suppressed neocortical activity during engagement. These results reveal organizing principles for the distribution of neurons encoding behaviourally relevant variables across the mouse brain.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Decision,Neural circuits},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Steinmetz et al_2019_Distributed coding of choice, action and engagement across the mouse brain.pdf}
}

@article{steinmetzNeuropixelsMiniaturized2021,
  title = {Neuropixels 2.0: {{A}} Miniaturized High-Density Probe for Stable, Long-Term Brain Recordings},
  shorttitle = {Neuropixels 2.0},
  author = {Steinmetz, Nicholas A. and Aydin, Cagatay and Lebedeva, Anna and Okun, Michael and Pachitariu, Marius and Bauza, Marius and Beau, Maxime and Bhagat, Jai and B{\"o}hm, Claudia and Broux, Martijn and Chen, Susu and Colonell, Jennifer and Gardner, Richard J. and Karsh, Bill and Kloosterman, Fabian and Kostadinov, Dimitar and {Mora-Lopez}, Carolina and O'Callaghan, John and Park, Junchol and Putzeys, Jan and Sauerbrei, Britton and {van Daal}, Rik J. J. and Vollan, Abraham Z. and Wang, Shiwei and Welkenhuysen, Marleen and Ye, Zhiwen and Dudman, Joshua T. and Dutta, Barundeb and Hantman, Adam W. and Harris, Kenneth D. and Lee, Albert K. and Moser, Edvard I. and O'Keefe, John and Renart, Alfonso and Svoboda, Karel and H{\"a}usser, Michael and Haesler, Sebastian and Carandini, Matteo and Harris, Timothy D.},
  year = {2021},
  month = apr,
  journal = {Science},
  volume = {372},
  number = {6539},
  pages = {eabf4588},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.abf4588}
}

@article{stringerHighprecisionCoding2021,
  title = {High-Precision Coding in Visual Cortex},
  author = {Stringer, Carsen and Michaelos, Michalis and Tsyboulski, Dmitri and Lindo, Sarah E. and Pachitariu, Marius},
  year = {2021},
  month = may,
  journal = {Cell},
  volume = {184},
  number = {10},
  pages = {2767-2778.e15},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2021.03.042},
  abstract = {Individual neurons in visual cortex provide the brain with unreliable estimates of visual features. It is not known whether the single-neuron variability is correlated across large neural populations, thus impairing the global encoding of stimuli. We recorded simultaneously from up to 50,000 neurons in mouse primary visual cortex (V1) and in higher order visual areas and measured stimulus discrimination thresholds of 0.35\textdegree{} and 0.37\textdegree, respectively, in an orientation decoding task. These neural thresholds were almost 100 times smaller than the behavioral discrimination thresholds reported in mice. This discrepancy could not be explained by stimulus properties or arousal states. Furthermore, behavioral variability during a sensory discrimination task could not be explained by neural variability in V1. Instead, behavior-related neural activity arose dynamically across a network of non-sensory brain areas. These results imply that perceptual discrimination in mice is limited by downstream decoders, not by neural noise in sensory representations.},
  langid = {english},
  keywords = {information theory,large-scale neural recordings,population coding,visual cortex}
}

@article{taherkhaniReviewLearning2020,
  title = {A Review of Learning in Biologically Plausible Spiking Neural Networks},
  author = {Taherkhani, Aboozar and Belatreche, Ammar and Li, Yuhua and Cosma, Georgina and Maguire, Liam P. and McGinnity, T. M.},
  year = {2020},
  month = feb,
  journal = {Neural Networks},
  volume = {122},
  pages = {253--272},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2019.09.036},
  abstract = {Artificial neural networks have been used as a powerful processing tool in various areas such as pattern recognition, control, robotics, and bioinformatics. Their wide applicability has encouraged researchers to improve artificial neural networks by investigating the biological brain. Neurological research has significantly progressed in recent years and continues to reveal new characteristics of biological neurons. New technologies can now capture temporal changes in the internal activity of the brain in more detail and help clarify the relationship between brain activity and the perception of a given stimulus. This new knowledge has led to a new type of artificial neural network, the Spiking Neural Network (SNN), that draws more faithfully on biological properties to provide higher processing abilities. A review of recent developments in learning of spiking neurons is presented in this paper. First the biological background of SNN learning algorithms is reviewed. The important elements of a learning algorithm such as the neuron model, synaptic plasticity, information encoding and SNN topologies are then presented. Then, a critical review of the state-of-the-art learning algorithms for SNNs using single and multiple spikes is presented. Additionally, deep spiking neural networks are reviewed, and challenges and opportunities in the SNN field are discussed.},
  langid = {english},
  keywords = {Learning,Spiking neural network (SNN),Synaptic plasticity}
}

@article{takeiSinglecellNuclear2021,
  title = {Single-Cell Nuclear Architecture across Cell Types in the Mouse Brain},
  author = {Takei, Yodai and Zheng, Shiwei and Yun, Jina and Shah, Sheel and Pierson, Nico and White, Jonathan and Schindler, Simone and Tischbirek, Carsten H. and Yuan, Guo-Cheng and Cai, Long},
  year = {2021},
  journal = {Science},
  volume = {0},
  number = {0},
  pages = {eabj1966},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.abj1966},
  file = {/Users/chaichontat/OneDrive - Johns Hopkins/Apps/ZoteroFiles/PhD/Takei et al_Single-cell nuclear architecture across cell types in the mouse brain2.pdf}
}

@article{thompsonFormsExplanation2021,
  title = {Forms of Explanation and Understanding for Neuroscience and Artificial Intelligence},
  author = {Thompson, Jessica A. F.},
  year = {2021},
  month = dec,
  journal = {Journal of Neurophysiology},
  volume = {126},
  number = {6},
  pages = {1860--1874},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.00195.2021},
  abstract = {Much of the controversy evoked by the use of deep neural networks as models of biological neural systems amount to debates over what constitutes scientific progress in neuroscience. To discuss what constitutes scientific progress, one must have a goal in mind (progress toward what?). One such long-term goal is to produce scientific explanations of intelligent capacities (e.g., object recognition, relational reasoning). I argue that the most pressing philosophical questions at the intersection of neuroscience and artificial intelligence are ultimately concerned with defining the phenomena to be explained and with what constitute valid explanations of such phenomena. I propose that a foundation in the philosophy of scientific explanation and understanding can scaffold future discussions about how an integrated science of intelligence might progress. Toward this vision, I review relevant theories of scientific explanation and discuss strategies for unifying the scientific goals of neuroscience and AI.},
  keywords = {causality,deep learning,explanation,intelligibility,understanding}
}

@article{uraiLargescaleNeural2021,
  title = {Large-Scale Neural Recordings Call for New Insights to Link Brain and Behavior},
  author = {Urai, Anne E. and Doiron, Brent and Leifer, Andrew M. and Churchland, Anne K.},
  year = {2021},
  month = jul,
  journal = {arXiv:2103.14662 [q-bio]},
  eprint = {2103.14662},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  abstract = {Neuroscientists today can measure activity from more neurons than ever before, and are facing the challenge of connecting these brain-wide neural recordings to computation and behavior. Here, we first describe emerging tools and technologies being used to probe large-scale brain activity and new approaches to characterize behavior in the context of such measurements. We next highlight insights obtained from large-scale neural recordings in diverse model systems, and argue that some of these pose a challenge to traditional theoretical frameworks. Finally, we elaborate on existing modelling frameworks to interpret these data, and argue that interpreting brain-wide neural recordings calls for new theoretical approaches that may depend on the desired level of understanding at stake. These advances in both neural recordings and theory development will pave the way for critical advances in our understanding of the brain.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Urai et al_2021_Large-scale neural recordings call for new insights to link brain and behavior.pdf}
}

@misc{ustyuzhaninovDigitalTwin2022,
  title = {Digital Twin Reveals Combinatorial Code of Non-Linear Computations in the Mouse Primary Visual Cortex},
  author = {Ustyuzhaninov, Ivan and Burg, Max F. and Cadena, Santiago A. and Fu, Jiakun and Muhammad, Taliah and Ponder, Kayla and Froudarakis, Emmanouil and Ding, Zhiwei and Bethge, Matthias and Tolias, Andreas S. and Ecker, Alexander S.},
  year = {2022},
  month = feb,
  pages = {2022.02.10.479884},
  institution = {{bioRxiv}},
  doi = {10.1101/2022.02.10.479884},
  abstract = {More than a dozen excitatory cell types have been identified in the mouse primary visual cortex (V1) based on transcriptomic, morphological and in vitro electrophysiological features. However, the functional landscape of excitatory neurons with respect to their responses to visual stimuli is currently unknown. Here, we combined large-scale two-photon imaging and deep learning neural predictive models to study the functional organization of mouse V1 using digital twins. Digital twins enable exhaustive in silico functional characterization providing a bar code summarizing the input-output function of each neuron. Clustering the bar codes revealed a continuum of function with around 30 modes. Each mode represented a group of neurons that exhibited a specific combination of stimulus selectivity and nonlinear response properties such as cross-orientation inhibition, size-contrast tuning and surround suppression. These non-linear properties were expressed independently spanning all possible combinations across the population. This combinatorial code provides the first large-scale, data-driven characterization of the functional organization of V1. This powerful approach based on digital twins is applicable to other brain areas and to complex non-linear systems beyond the brain.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Ustyuzhaninov et al_2022_Digital twin reveals combinatorial code of non-linear computations in the mouse.pdf}
}

@article{walkerInceptionLoops2019,
  title = {Inception Loops Discover What Excites Neurons Most Using Deep Predictive Models},
  author = {Walker, Edgar Y. and Sinz, Fabian H. and Cobos, Erick and Muhammad, Taliah and Froudarakis, Emmanouil and Fahey, Paul G. and Ecker, Alexander S. and Reimer, Jacob and Pitkow, Xaq and Tolias, Andreas S.},
  year = {2019},
  month = dec,
  journal = {Nat Neurosci},
  volume = {22},
  number = {12},
  pages = {2060--2065},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0517-x},
  abstract = {Finding sensory stimuli that drive neurons optimally is central to understanding information processing in the brain. However, optimizing sensory input is difficult due to the predominantly nonlinear nature of sensory processing and high dimensionality of the input. We developed `inception loops', a closed-loop experimental paradigm combining in vivo recordings from thousands of neurons with in silico nonlinear response modeling. Our end-to-end trained, deep-learning-based model predicted thousands of neuronal responses to arbitrary, new natural input with high accuracy and was used to synthesize optimal stimuli\textemdash most exciting inputs (MEIs). For mouse primary visual cortex (V1), MEIs exhibited complex spatial features that occurred frequently in natural scenes but deviated strikingly from the common notion that Gabor-like stimuli are optimal for V1. When presented back to the same neurons in vivo, MEIs drove responses significantly better than control stimuli. Inception loops represent a widely applicable technique for dissecting the neural mechanisms of sensation.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Network models,Neural encoding,Neuroscience,Striate cortex,Visual system}
}

@inproceedings{whittingtonRelatingTransformers2021,
  title = {Relating Transformers to Models and Neural Representations of the Hippocampal Formation},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Whittington, James C. R. and Warren, Joseph and Behrens, Tim E. J.},
  year = {2021},
  month = sep,
  abstract = {Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising...},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Whittington et al_2021_Relating transformers to models and neural representations of the hippocampal.pdf}
}

@article{winnubstLinkingAxon2020,
  title = {Linking Axon Morphology to Gene Expression: A Strategy for Neuronal Cell-Type Classification},
  shorttitle = {Linking Axon Morphology to Gene Expression},
  author = {Winnubst, Johan and Spruston, Nelson and Harris, Julie A},
  year = {2020},
  month = dec,
  journal = {Current Opinion in Neurobiology},
  series = {Whole-Brain Interactions between Neural Circuits},
  volume = {65},
  pages = {70--76},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2020.10.006},
  abstract = {To study how the brain drives cognition and behavior we need to understand its cellular composition. Advances in single-cell transcriptomics have revolutionized our ability to characterize neuronal diversity. To arrive at meaningful descriptions of cell types, however, gene expression must be linked to structural and functional properties. Axonal projection patterns are an appropriate measure, as they are diverse, change only gradually over time, and they influence and constrain circuit function. Here, we consider how efforts to map transcriptional and morphological diversity in the mouse brain could be linked to generate a modern taxonomy of the mouse brain.},
  langid = {english}
}

@article{xuLimitsVisual2021,
  title = {Limits to Visual Representational Correspondence between Convolutional Neural Networks and the Human Brain},
  author = {Xu, Yaoda and {Vaziri-Pashkam}, Maryam},
  year = {2021},
  month = apr,
  journal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2065},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22244-7},
  abstract = {Convolutional neural networks (CNNs) are increasingly used to model human vision due to their high object categorization capabilities and general correspondence with human brain responses. Here we evaluate the performance of 14 different CNNs compared with human fMRI responses to natural and artificial images using representational similarity analysis. Despite the presence of some CNN-brain correspondence and CNNs' impressive ability to fully capture lower level visual representation of real-world objects, we show that CNNs do not fully capture higher level visual representations of real-world objects, nor those of artificial objects, either at lower or higher levels of visual representations. The latter is particularly critical, as the processing of both real-world and artificial visual stimuli engages the same neural circuits. We report similar results regardless of differences in CNN architecture, training, or the presence of recurrent processing. This indicates some fundamental differences exist in how the brain and CNNs represent visual information.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Neural decoding,Object vision}
}

@article{yaminsUsingGoaldriven2016,
  title = {Using Goal-Driven Deep Learning Models to Understand Sensory Cortex},
  author = {Yamins, Daniel L. K. and DiCarlo, James J.},
  year = {2016},
  month = mar,
  journal = {Nat Neurosci},
  volume = {19},
  number = {3},
  pages = {356--365},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4244},
  abstract = {Recent computational neuroscience developments have used deep neural networks to model neural responses in higher visual areas. This Perspective describes key algorithmic underpinnings in computer vision and artificial intelligence that have contributed to this progress and outlines how deep networks could drive future improvements in understanding sensory cortical processing.},
  copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Computational neuroscience,Object vision},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Yamins_DiCarlo_2016_Using goal-driven deep learning models to understand sensory cortex.pdf}
}

@article{yangArtificialNeural2020,
  title = {Artificial {{Neural Networks}} for {{Neuroscientists}}: {{A Primer}}},
  shorttitle = {Artificial {{Neural Networks}} for {{Neuroscientists}}},
  author = {Yang, Guangyu Robert and Wang, Xiao-Jing},
  year = {2020},
  month = sep,
  journal = {Neuron},
  volume = {107},
  number = {6},
  pages = {1048--1070},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.09.005},
  abstract = {Artificial neural networks (ANNs) are essential tools in machine learning that have drawn increasing attention in neuroscience. Besides offering powerful techniques for data analysis, ANNs provide a new approach for neuroscientists to build models for complex behaviors, heterogeneous neural activity, and circuit connectivity, as well as to explore optimization in neural systems, in ways that traditional models are not designed for. In this pedagogical Primer, we introduce ANNs and demonstrate how they have been fruitfully deployed to study neuroscientific questions. We first discuss basic concepts and methods of ANNs. Then, with a focus on bringing this mathematical framework closer to neurobiology, we detail how to customize the analysis, structure, and learning of ANNs to better address a wide range of challenges in brain research. To help readers garner hands-on experience, this Primer is accompanied with tutorial-style code in PyTorch and Jupyter Notebook, covering major topics.},
  langid = {english},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Yang_Wang_2020_Artificial Neural Networks for Neuroscientists.pdf}
}

@article{yangTaskRepresentations2019,
  title = {Task Representations in Neural Networks Trained to Perform Many Cognitive Tasks},
  author = {Yang, Guangyu Robert and Joglekar, Madhura R. and Song, H. Francis and Newsome, William T. and Wang, Xiao-Jing},
  year = {2019},
  month = feb,
  journal = {Nat Neurosci},
  volume = {22},
  number = {2},
  pages = {297--306},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0310-2},
  abstract = {Prefrontal cortex can be flexibly engaged in many different tasks. Yang et al. trained an artificial neural network to solve 20 cognitive tasks. Functionally specialized modules and compositional representations emerged in the network after training.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Cognitive neuroscience,Network models}
}

@article{yaoTaxonomyTranscriptomic2021,
  title = {A Taxonomy of Transcriptomic Cell Types across the Isocortex and Hippocampal Formation},
  author = {Yao, Zizhen and {van Velthoven}, Cindy T. J. and Nguyen, Thuc Nghi and Goldy, Jeff and {Sedeno-Cortes}, Adriana E. and Baftizadeh, Fahimeh and Bertagnolli, Darren and Casper, Tamara and Chiang, Megan and Crichton, Kirsten and Ding, Song-Lin and Fong, Olivia and Garren, Emma and Glandon, Alexandra and Gouwens, Nathan W. and Gray, James and Graybuck, Lucas T. and Hawrylycz, Michael J. and Hirschstein, Daniel and Kroll, Matthew and Lathia, Kanan and Lee, Changkyu and Levi, Boaz and McMillen, Delissa and Mok, Stephanie and Pham, Thanh and Ren, Qingzhong and Rimorin, Christine and Shapovalova, Nadiya and Sulc, Josef and Sunkin, Susan M. and Tieu, Michael and Torkelson, Amy and Tung, Herman and Ward, Katelyn and Dee, Nick and Smith, Kimberly A. and Tasic, Bosiljka and Zeng, Hongkui},
  year = {2021},
  month = jun,
  journal = {Cell},
  volume = {184},
  number = {12},
  pages = {3222-3241.e26},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2021.04.021},
  abstract = {The isocortex and hippocampal formation (HPF) in the mammalian brain play critical roles in perception, cognition, emotion, and learning. We profiled {$\sim$}1.3 million cells covering the entire adult mouse isocortex and HPF and derived a transcriptomic cell-type taxonomy revealing a comprehensive repertoire of glutamatergic and GABAergic neuron types. Contrary to the traditional view of HPF as having a simpler cellular organization, we discover a complete set of glutamatergic types in HPF homologous to all major subclasses found in the six-layered isocortex, suggesting that HPF and the isocortex share a common circuit organization. We also identify large-scale continuous and graded variations of cell types along isocortical depth, across the isocortical sheet, and in multiple dimensions in hippocampus and subiculum. Overall, our study establishes a molecular architecture of the mammalian isocortex and hippocampal formation and begins to shed light on its underlying relationship with the development, evolution, connectivity, and function of these two brain structures.},
  langid = {english},
  keywords = {cell type,cortex,excitatory neuron,GABAergic,glutamatergic,hippocampus,interneuron,single-cell RNA sequencing,single-cell transcriptomics}
}

@article{yarkoniChoosingPrediction2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  month = nov,
  journal = {Perspect Psychol Sci},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691617693393},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  keywords = {explanation,machine learning,prediction},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Yarkoni_Westfall_2017_Choosing Prediction Over Explanation in Psychology.pdf}
}

@inproceedings{youDesignSpace2020,
  title = {Design {{Space}} for {{Graph Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {You, Jiaxuan and Ying, Zhitao and Leskovec, Jure},
  year = {2020},
  volume = {33},
  pages = {17009--17021},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/You et al_2020_Design Space for Graph Neural Networks.pdf}
}

@article{zhuangUnsupervisedNeural2021,
  title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
  author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
  year = {2021},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {3},
  pages = {e2014196118},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2014196118},
  file = {/Users/chaichontat/Library/Mobile Documents/com~apple~CloudDocs/Apps/ZoteroFiles/PhD/Zhuang et al_2021_Unsupervised neural network models of the ventral visual stream.pdf}
}
